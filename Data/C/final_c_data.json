{
    "c_2": {
        "input": "/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#ifndef TENSORFLOW_C_EXPERIMENTAL_OPS_GEN_CPP_CPP_CONFIG_H_\n#define TENSORFLOW_C_EXPERIMENTAL_OPS_GEN_CPP_CPP_CONFIG_H_\n\n#include \"tensorflow/core/platform/types.h\"\n\nnamespace tensorflow {\nnamespace generator {\nnamespace cpp {\n\nstruct CppConfig {\n  string category;\n  string unit;\n  std::vector<string> namespaces;\n\n  explicit CppConfig() = default;\n  explicit CppConfig(const string &category,\n                     const string &name_space = \"tensorflow::ops\");\n};\n\n}  // namespace cpp\n}  // namespace generator\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_C_EXPERIMENTAL_OPS_GEN_CPP_CPP_CONFIG_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_GUARD\",\n        \"component_name\": \"TENSORFLOW_C_EXPERIMENTAL_OPS_GEN_CPP_CPP_CONFIG_H_\",\n        \"component_code\": \"#ifndef TENSORFLOW_C_EXPERIMENTAL_OPS_GEN_CPP_CPP_CONFIG_H_\\n#define TENSORFLOW_C_EXPERIMENTAL_OPS_GEN_CPP_CPP_CONFIG_H_\\n#endif  // TENSORFLOW_C_EXPERIMENTAL_OPS_GEN_CPP_CPP_CONFIG_H_\",\n        \"component_description\": \"A header guard to prevent multiple inclusions of the header file, ensuring that the contents are only processed once during compilation.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": \"tensorflow/core/platform/types.h\",\n        \"component_code\": \"#include \\\"tensorflow/core/platform/types.h\\\"\",\n        \"component_description\": \"Includes a header file from TensorFlow's core platform that likely defines fundamental types used in the codebase.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DEFINITION\",\n        \"component_name\": \"tensorflow\",\n        \"component_code\": \"namespace tensorflow {\\n}\",\n        \"component_description\": \"Defines the 'tensorflow' namespace, encapsulating all subsequent declarations within it to avoid name collisions with other libraries or user code.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DEFINITION\",\n        \"component_name\": \"generator\",\n        \"component_code\": \"namespace generator {\\n}\",\n        \"component_description\": \"Defines the 'generator' namespace within 'tensorflow', further encapsulating declarations related to code generation functionalities.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DEFINITION\",\n        \"component_name\": \"cpp\",\n        \"component_code\": \"namespace cpp {\\n}\",\n        \"component_description\": \"Defines the 'cpp' namespace within 'tensorflow::generator', specifically for C++-related code generation functionalities.\"\n      },\n      {\n        \"component_type\": \"STRUCT_DEFINITION\",\n        \"component_name\": \"CppConfig\",\n        \"component_code\": \"struct CppConfig {\\n  string category;\\n  string unit;\\n  std::vector<string> namespaces;\\n\\n  explicit CppConfig() = default;\\n  explicit CppConfig(const string &category,\\n                     const string &name_space = \\\"tensorflow::ops\\\");\\n};\",\n        \"component_description\": \"Defines a struct named 'CppConfig' within the 'tensorflow::generator::cpp' namespace. It contains three members: 'category', 'unit', and 'namespaces'. The struct provides two constructors: a default constructor that initializes the object with default values, and another constructor that allows setting initial values for 'category' and optionally 'name_space'.\"\n      }\n    ],\n    \"overall_description\": \"This header file defines a configuration structure named 'CppConfig' within the 'tensorflow::generator::cpp' namespace. The purpose of this structure is to hold settings related to C++ code generation, such as category, unit, and namespaces. It includes an explicit default constructor and another constructor for initializing these settings. The use of namespaces helps in organizing the code and avoiding name conflicts with other parts of the TensorFlow library or external libraries.\"\n  }\n}"
    },
    "c_3": {
        "input": "<reponame>EricRemmerswaal/tensorflow\n/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_CORE_KERNELS_SPARSE_REORDER_OP_H_\n#define TENSORFLOW_CORE_KERNELS_SPARSE_REORDER_OP_H_\n\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nnamespace tensorflow {\n\nnamespace functor {\n\ntemplate <typename Device, typename T>\nstruct SparseReorderFunctor {\n  void operator()(OpKernelContext* context, const Tensor& input_ind,\n                  const Tensor& input_val, const Tensor& input_shape_in);\n};\n\n}  // namespace functor\n\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_KERNELS_SPARSE_REORDER_OP_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/framework/op_kernel.h\\\"\",\n        \"component_description\": \"Includes the header file for OpKernel, which is a base class for TensorFlow operations that operate on Tensors.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DEFINITION\",\n        \"component_name\": \"tensorflow\",\n        \"component_code\": \"namespace tensorflow { ... }\",\n        \"component_description\": \"Defines the 'tensorflow' namespace to encapsulate all components related to TensorFlow's core functionalities.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DEFINITION\",\n        \"component_name\": \"functor\",\n        \"component_code\": \"namespace functor { ... }\",\n        \"component_description\": \"Defines a nested 'functor' namespace within the 'tensorflow' namespace, typically used for defining function objects or functors.\"\n      },\n      {\n        \"component_type\": \"TEMPLATE_STRUCT_DEFINITION\",\n        \"component_name\": \"SparseReorderFunctor\",\n        \"component_code\": \"template <typename Device, typename T> struct SparseReorderFunctor { ... };\",\n        \"component_description\": \"Defines a template struct named 'SparseReorderFunctor' that is parameterized by 'Device' and 'T'. This functor is designed to reorder sparse data structures in TensorFlow operations.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"operator()\",\n        \"component_code\": \"void operator()(OpKernelContext* context, const Tensor& input_ind, const Tensor& input_val, const Tensor& input_shape_in);\",\n        \"component_description\": \"Defines the function call operator for 'SparseReorderFunctor'. This operator takes an OpKernelContext pointer and three constant Tensors as parameters, which represent indices, values, and shape of a sparse tensor respectively. It is used to reorder these sparse data components.\"\n      }\n    ],\n    \"overall_description\": \"The provided C++ code snippet defines a header file for TensorFlow that introduces a template struct named 'SparseReorderFunctor'. This functor is designed to handle the reordering of sparse tensors within TensorFlow operations. The code includes necessary headers, uses namespaces to avoid name clashes, and outlines the functionality through a function call operator that takes a context and three tensor inputs.\"\n  }\n}"
    },
    "c_5": {
        "input": "/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#ifndef TENSORFLOW_CC_EXPERIMENTAL_LIBEXPORT_SAVE_H_\n#define TENSORFLOW_CC_EXPERIMENTAL_LIBEXPORT_SAVE_H_\n\n#include <string>\n\n#include \"tensorflow/core/platform/status.h\"\n\nnamespace tensorflow {\nnamespace libexport {\n\n// Writes a saved model to disk.\n//\n// Writes a saved model to the given `export_dir`.\nTF_EXPORT Status Save(const std::string& export_dir);\n\n}  // namespace libexport\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CC_EXPERIMENTAL_EXPORT_EXPORT_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": \"string\",\n        \"component_code\": \"#include <string>\",\n        \"component_description\": \"Includes the C++ Standard Library string header, providing facilities to manipulate strings.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": \"tensorflow/core/platform/status.h\",\n        \"component_code\": \"#include \\\"tensorflow/core/platform/status.h\\\"\",\n        \"component_description\": \"Includes a TensorFlow-specific header that defines the Status class used for error handling in TensorFlow operations.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DEFINITION\",\n        \"component_name\": \"tensorflow\",\n        \"component_code\": \"namespace tensorflow { ... }\",\n        \"component_description\": \"Defines a namespace named 'tensorflow' to encapsulate code related to TensorFlow functionalities, avoiding name collisions with other libraries.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DEFINITION\",\n        \"component_name\": \"libexport\",\n        \"component_code\": \"namespace libexport { ... }\",\n        \"component_description\": \"Defines a nested namespace named 'libexport' within the 'tensorflow' namespace to encapsulate code related to exporting functionalities of TensorFlow.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"Save\",\n        \"component_code\": \"TF_EXPORT Status Save(const std::string& export_dir);\",\n        \"component_description\": \"Declares a function named 'Save' that takes a constant reference to a string representing the export directory. It returns a Status object indicating the result of writing a saved model to the specified directory.\"\n      }\n    ],\n    \"overall_description\": \"This C++ header file defines an interface for exporting TensorFlow models. It includes necessary headers, encapsulates the code within 'tensorflow::libexport' namespaces, and declares a function named 'Save'. The 'Save' function is designed to write a saved model to a specified directory on disk and returns a Status object to indicate the success or failure of the operation.\"\n  }\n}"
    },
    "c_6": {
        "input": "<gh_stars>1000+\n/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#ifndef TENSORFLOW_LITE_EXPERIMENTAL_DELEGATES_COREML_BUILDERS_CONVOLUTION_OP_BUILDER_H_\n#define TENSORFLOW_LITE_EXPERIMENTAL_DELEGATES_COREML_BUILDERS_CONVOLUTION_OP_BUILDER_H_\n\n#include \"tensorflow/lite/builtin_ops.h\"\n#include \"tensorflow/lite/c/builtin_op_data.h\"\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/delegates/coreml/builders/op_builder.h\"\n\nnamespace tflite {\nnamespace delegates {\nnamespace coreml {\n\nenum class ConvolutionType { kConv, kDepthwiseConv, kTransposeConv };\n\n// Layer that provides convolution and depthwise convolution.\nclass ConvolutionOpBuilder : public OpBuilder {\n public:\n  explicit ConvolutionOpBuilder(GraphBuilder* graph_builder,\n                                ConvolutionType conv_type)\n      : OpBuilder(graph_builder), conv_type_(conv_type) {}\n\n  const std::string& DebugName() override;\n\n  CoreML::Specification::NeuralNetworkLayer* Build() override;\n\n  TfLiteStatus PopulateSubgraph(TfLiteContext* context) override;\n\n  void SetOutputChannels(uint64_t output_channels);\n\n  void SetNGroups(uint64_t n_groups);\n\n  void SetWeights(TfLiteTensor* weights);\n\n  void SetBias(TfLiteTensor* bias);\n\n  void SetOutputShape(TfLiteTensor* output_shape);\n\n  void SetParams(void* builtin_data);\n\n  TfLiteStatus RegisterInputs(const TfLiteIntArray* inputs,\n                              TfLiteContext* context) override;\n\n  TfLiteStatus RegisterOutputs(const TfLiteIntArray* outputs,\n                               TfLiteContext* context) override;\n\n private:\n  void FillCoreMLWeights();\n  void FillCoreMLBias();\n\n  // Transpose TFLite kernel weights to CoreML kernel weights.\n  // Should be called after setting CoreML's kernel shapes.\n  void TransposeKernelWeights();\n\n  uint64_t output_channels_;\n  uint64_t n_groups_ = 1;\n\n  ConvolutionType conv_type_;\n\n  // using default dilation_factor (1, 1)\n  // CoreML ConvolutionLayerParams.isDeconvolution == false\n  TfLiteTensor* weights_ = nullptr;\n  TfLiteTensor* bias_ = nullptr;\n  // Only used for TransposeConv.\n  TfLiteTensor* output_shape_ = nullptr;\n};\n\n}  // namespace coreml\n}  // namespace delegates\n}  // namespace tflite\n\n#endif  // TENSORFLOW_LITE_EXPERIMENTAL_DELEGATES_COREML_BUILDERS_CONVOLUTION_OP_BUILDER_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": null,\n        \"component_code\": \"#include \\\"tensorflow/lite/builtin_ops.h\\\"\",\n        \"component_description\": \"Includes the header file that defines constants and data structures for TensorFlow Lite's built-in operations.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": null,\n        \"component_code\": \"#include \\\"tensorflow/lite/c/builtin_op_data.h\\\"\",\n        \"component_description\": \"Includes the header file that provides C-style data structures for built-in operator data in TensorFlow Lite.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": null,\n        \"component_code\": \"#include \\\"tensorflow/lite/c/common.h\\\"\",\n        \"component_description\": \"Includes the common header file for TensorFlow Lite's C API, providing general utilities and definitions.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": null,\n        \"component_code\": \"#include \\\"tensorflow/lite/delegates/coreml/builders/op_builder.h\\\"\",\n        \"component_description\": \"Includes the header file that defines the base class for operation builders in TensorFlow Lite's Core ML delegate.\"\n      },\n      {\n        \"component_type\": \"ENUM_DEFINITION\",\n        \"component_name\": \"ConvolutionType\",\n        \"component_code\": \"enum class ConvolutionType { kConv, kDepthwiseConv, kTransposeConv };\",\n        \"component_description\": \"Defines an enumeration representing different types of convolution operations: standard convolution (kConv), depthwise convolution (kDepthwiseConv), and transposed convolution (kTransposeConv).\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"ConvolutionOpBuilder\",\n        \"component_code\": \"class ConvolutionOpBuilder : public OpBuilder { ... };\",\n        \"component_description\": \"Defines a class named ConvolutionOpBuilder that inherits from OpBuilder. This class is responsible for building Core ML layers corresponding to convolution operations in TensorFlow Lite.\"\n      },\n      {\n        \"component_type\": \"CONSTRUCTOR\",\n        \"component_name\": \"ConvolutionOpBuilder\",\n        \"component_code\": \"explicit ConvolutionOpBuilder(GraphBuilder* graph_builder, ConvolutionType conv_type) : OpBuilder(graph_builder), conv_type_(conv_type) {}\",\n        \"component_description\": \"Constructor for the ConvolutionOpBuilder class. Initializes the base class with a pointer to a GraphBuilder and sets the type of convolution operation.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"DebugName\",\n        \"component_code\": \"const std::string& DebugName() override;\",\n        \"component_description\": \"Pure virtual function that overrides OpBuilder's DebugName method. Returns a string representing the debug name of the operation builder.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"Build\",\n        \"component_code\": \"CoreML::Specification::NeuralNetworkLayer* Build() override;\",\n        \"component_description\": \"Pure virtual function that overrides OpBuilder's Build method. Constructs and returns a pointer to the Core ML neural network layer corresponding to the convolution operation.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"PopulateSubgraph\",\n        \"component_code\": \"TfLiteStatus PopulateSubgraph(TfLiteContext* context) override;\",\n        \"component_description\": \"Pure virtual function that overrides OpBuilder's PopulateSubgraph method. Populates a subgraph in the TensorFlow Lite context with nodes and tensors required for the convolution operation.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"SetOutputChannels\",\n        \"component_code\": \"void SetOutputChannels(uint64_t output_channels);\",\n        \"component_description\": \"Function to set the number of output channels for the convolution layer.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"SetNGroups\",\n        \"component_code\": \"void SetNGroups(uint64_t n_groups);\",\n        \"component_description\": \"Function to set the number of groups for grouped convolutions, used in depthwise convolution.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"SetWeights\",\n        \"component_code\": \"void SetWeights(TfLiteTensor* weights);\",\n        \"component_description\": \"Function to set the tensor containing the weights of the convolution layer.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"SetBias\",\n        \"component_code\": \"void SetBias(TfLiteTensor* bias);\",\n        \"component_description\": \"Function to set the tensor containing the biases for the convolution layer.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"SetOutputShape\",\n        \"component_code\": null,\n        \"component_description\": \"Implicit function (not explicitly shown in code) that would be used to set the output shape of the convolution operation, typically part of the builder's implementation.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"TransposeWeights\",\n        \"component_code\": null,\n        \"component_description\": \"Implicit function (not explicitly shown in code) that would be used to transpose weights if necessary for Core ML compatibility, typically part of the builder's implementation.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"RegisterInputsOutputs\",\n        \"component_code\": null,\n        \"component_description\": \"Implicit function (not explicitly shown in code) that would be used to register inputs and outputs of the convolution layer, typically part of the builder's implementation.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"SetOutputShape\",\n        \"component_code\": null,\n        \"component_description\": \"Implicit function (not explicitly shown in code) that would be used to set the output shape of the convolution operation, typically part of the builder's implementation.\"\n      },\n      {\n        \"component_type\": \"MEMBER_VARIABLE\",\n        \"component_name\": \"conv_type_\",\n        \"component_code\": null,\n        \"component_description\": \"Member variable (not explicitly shown in code) that holds the type of convolution operation, initialized in the constructor.\"\n      },\n      {\n        \"component_type\": \"MEMBER_VARIABLE\",\n        \"component_name\": \"output_channels_\",\n        \"component_code\": null,\n        \"component_description\": \"Member variable (not explicitly shown in code) that stores the number of output channels for the convolution layer.\"\n      },\n      {\n        \"component_type\": \"MEMBER_VARIABLE\",\n        \"component_name\": \"n_groups_\",\n        \"component_code\": null,\n        \"component_description\": \"Member variable (not explicitly shown in code) that holds the number of groups used in grouped convolutions, such as depthwise convolution.\"\n      },\n      {\n        \"component_type\": \"MEMBER_VARIABLE\",\n        \"component_name\": \"weights_\",\n        \"component_code\": null,\n        \"component_description\": \"Member variable (not explicitly shown in code) that stores a pointer to the tensor containing the weights for the convolution layer.\"\n      },\n      {\n        \"component_type\": \"MEMBER_VARIABLE\",\n        \"component_name\": \"bias_\",\n        \"component_code\": null,\n        \"component_description\": \"Member variable (not explicitly shown in code) that stores a pointer to the tensor containing the biases for the convolution layer.\"\n      }\n    ],\n    \"description\": \"This header file defines the ConvolutionOpBuilder class, which is responsible for constructing Core ML layers corresponding to different types of convolution operations in TensorFlow Lite. The builder supports standard convolution, depthwise convolution, and transposed convolution by setting various parameters such as weights, biases, output channels, and groups.\"\n  }\n}"
    },
    "c_7": {
        "input": "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_CORE_FRAMEWORK_RUN_HANDLER_H_\n#define TENSORFLOW_CORE_FRAMEWORK_RUN_HANDLER_H_\n\n#include \"tensorflow/core/lib/core/threadpool.h\"\n#include \"tensorflow/core/lib/histogram/histogram.h\"\n#include \"tensorflow/core/platform/context.h\"\n#include \"tensorflow/core/platform/mutex.h\"\n#include \"tensorflow/core/platform/thread_annotations.h\"\n#include \"tensorflow/core/protobuf/config.pb.h\"\n\nnamespace Eigen {\nstruct ThreadPoolDevice;\n}\n\nnamespace tensorflow {\n\nclass RunHandler;\n\n// RunHandlerPool is a fixed size pool of pre-allocated RunHandlers\n// that can be used for tracking inter-op work for a given Session::Run().\n// RunHandler(s) in the pool are initially 'inactive'. A RunHandler becomes\n// 'active' when its unique_ptr is returned by Get() and is being used by a\n// client. It becomes 'inactive' once more when its unique_ptr gets destroyed.\n//\n// Expected usage:\n//\n// * Create a single RunHandlerPool (say run_handler_pool_).\n//\n// * When a Session::Run() is invoked, obtain a handler by:\n// auto handler = run_handler_pool_->Get();\n//\n// * Use handler for scheduling all inter-op work by:\n// handler->ScheduleInterOpClosure(closure);\n//\n// This class is thread safe.\nclass RunHandlerPool {\n public:\n  explicit RunHandlerPool(int num_inter_op_threads);\n\n  RunHandlerPool(int num_inter_op_threads, int num_intra_op_threads);\n  ~RunHandlerPool();\n\n  // Returns an inactive RunHandler from the pool.\n  //\n  // RunHandlers in RunHandlerPool are initially 'inactive'.\n  // A RunHandler becomes 'active' when its unique_ptr its returned by Get()\n  // and is being used by a client.  It becomes 'inactive' once more when the\n  // unique_ptr is destroyed.\n  //\n  // Will block unless there is an inactive handler.\n  std::unique_ptr<RunHandler> Get(\n      int64_t step_id = 0, int64_t timeout_in_ms = 0,\n      const RunOptions::Experimental::RunHandlerPoolOptions& options =\n          RunOptions::Experimental::RunHandlerPoolOptions());\n\n  // Get the priorities for active handlers. The return result is with the same\n  // order of the active handler list.\n  std::vector<int64_t> GetActiveHandlerPrioritiesForTesting() const;\n\n private:\n  class Impl;\n  friend class RunHandler;\n\n  std::unique_ptr<Impl> impl_;\n};\n\n// RunHandler can be used to schedule inter/intra-op closures to run on a global\n// pool shared across all Session::Run(s). The closures are enqueued to a\n// handler specific queue, from which the work is stolen in a priority order\n// (time of the Get() call).\n//\n// It can only be created via RunHandlerPool::Get().\n//\n// This class can be used instead of directly scheduling closures on a global\n// pool since it maintains a global view across all sessions and optimizes pool\n// scheduling to improve (median and tail) latency.\n//\n// This class is thread safe.\nclass RunHandler {\n public:\n  void ScheduleInterOpClosure(std::function<void()> fn);\n  thread::ThreadPoolInterface* AsIntraThreadPoolInterface();\n\n  ~RunHandler();\n\n private:\n  class Impl;\n  friend class RunHandlerPool::Impl;\n\n  explicit RunHandler(Impl* impl);\n\n  Impl* impl_;  // NOT OWNED.\n};\n\nnamespace internal {\n\n// TODO(azaks): Refactor with thread:ThreadPool\nclass RunHandlerEnvironment {\n  typedef Thread EnvThread;\n  struct TaskImpl {\n    std::function<void()> f;\n    Context context;\n    uint64 trace_id;\n  };\n  Env* const env_;\n  const ThreadOptions thread_options_;\n  const string name_;\n\n public:\n  struct Task {\n    std::unique_ptr<TaskImpl> f;\n  };\n\n  RunHandlerEnvironment(Env* env, const ThreadOptions& thread_options,\n                        const string& name);\n\n  EnvThread* CreateThread(std::function<void()> f,\n                          const std::string& thread_name);\n\n  Task CreateTask(std::function<void()> f);\n\n  void ExecuteTask(const Task& t);\n};\n\ntypedef typename RunHandlerEnvironment::Task Task;\ntypedef Eigen::RunQueue<Task, 1024> Queue;\n\n// To reduce cache misses, we use a doubly-linked list of Waiter structs and\n// queue them in LIFO order rather than the FIFO order used by a single\n// condition variable.\nstruct Waiter {\n  Waiter() {\n    next = this;\n    prev = this;\n  }\n  condition_variable cv;\n  mutex mu;\n  Waiter* next;\n  Waiter* prev;\n};\n\nclass ThreadWorkSource {\n public:\n  ThreadWorkSource();\n\n  ~ThreadWorkSource();\n\n  Task EnqueueTask(Task t, bool is_blocking);\n\n  Task PopBlockingTask();\n\n  Task PopNonBlockingTask(int start_index, bool search_from_all_queue);\n\n  void WaitForWork(int max_sleep_micros);\n\n  int TaskQueueSize(bool is_blocking);\n\n  int64_t GetTracemeId();\n\n  void SetTracemeId(int64_t value);\n\n  void SetWaiter(uint64 version, Waiter* waiter, mutex* mutex);\n\n  int64_t GetInflightTaskCount(bool is_blocking);\n\n  void IncrementInflightTaskCount(bool is_blocking);\n\n  void DecrementInflightTaskCount(bool is_blocking);\n\n  unsigned NonBlockingWorkShardingFactor();\n\n  std::string ToString();\n\n private:\n  struct NonBlockingQueue {\n    mutex queue_op_mu;\n    char pad[128];\n    Queue queue;\n  };\n\n  int32 non_blocking_work_sharding_factor_;\n  Eigen::MaxSizeVector<NonBlockingQueue*> non_blocking_work_queues_;\n\n  std::atomic<int64_t> blocking_inflight_;\n  std::atomic<int64_t> non_blocking_inflight_;\n\n  Queue blocking_work_queue_;\n  mutex blocking_queue_op_mu_;\n  char pad_[128];\n  mutex waiters_mu_;\n  Waiter queue_waiters_ TF_GUARDED_BY(waiters_mu_);\n  std::atomic<int64_t> traceme_id_;\n\n  mutex run_handler_waiter_mu_;\n  uint64 version_ TF_GUARDED_BY(run_handler_waiter_mu_);\n  mutex* sub_thread_pool_waiter_mu_ TF_GUARDED_BY(run_handler_waiter_mu_);\n  Waiter* sub_thread_pool_waiter_ TF_GUARDED_BY(run_handler_waiter_mu_);\n};\n\nclass RunHandlerThreadPool {\n public:\n  struct PerThread {\n    constexpr PerThread() : pool(nullptr), thread_id(-1) {}\n    RunHandlerThreadPool* pool;  // Parent pool, or null for normal threads.\n    int thread_id;               // Worker thread index in pool.\n  };\n\n  RunHandlerThreadPool(int num_blocking_threads, int num_non_blocking_threads,\n                       Env* env, const ThreadOptions& thread_options,\n                       const string& name,\n                       Eigen::MaxSizeVector<mutex>* waiters_mu,\n                       Eigen::MaxSizeVector<Waiter>* queue_waiters);\n\n  ~RunHandlerThreadPool();\n\n  void Start();\n\n  void StartOneThreadForTesting();\n\n  void AddWorkToQueue(ThreadWorkSource* tws, bool is_blocking,\n                      std::function<void()> fn);\n\n  // Set work queues from which the thread 'tid' can steal its work.\n  // The request with start_request_idx will be attempted first. Other requests\n  // will be attempted in FIFO order based on their arrival time.\n  void SetThreadWorkSources(\n      int tid, int start_request_idx, uint64 version,\n      const Eigen::MaxSizeVector<ThreadWorkSource*>& thread_work_sources);\n\n  PerThread* GetPerThread();\n\n  int CurrentThreadId() const;\n\n  int NumThreads() const;\n\n  int NumBlockingThreads() const;\n\n  int NumNonBlockingThreads() const;\n\n  void WorkerLoop(int thread_id, bool may_steal_blocking_work);\n\n  // Search tasks from Requets range searching_range_start to\n  // searching_range_end. If there is no tasks in the search range and\n  // may_steal_blocking_work is true, then search from all requests.\n  Task FindTask(\n      int searching_range_start, int searching_range_end, int thread_id,\n      int sub_thread_pool_id, int max_blocking_inflight,\n      bool may_steal_blocking_work,\n      const Eigen::MaxSizeVector<ThreadWorkSource*>& thread_work_sources,\n      bool* task_from_blocking_queue, ThreadWorkSource** tws);\n\n  void WaitForWork(bool is_blocking, int thread_id,\n                   int32_t max_blocking_inflight);\n\n  void WaitForWorkInSubThreadPool(bool is_blocking, int sub_thread_pool_id);\n\n private:\n  struct ThreadData {\n    ThreadData();\n    mutex mu;\n    uint64 new_version;\n    condition_variable sources_not_empty;\n    std::unique_ptr<Thread> thread;\n    int current_index;\n    std::unique_ptr<Eigen::MaxSizeVector<ThreadWorkSource*>>\n        new_thread_work_sources TF_GUARDED_BY(mu);\n\n    uint64 current_version;\n    // Should only be accessed by one thread.\n    std::unique_ptr<Eigen::MaxSizeVector<ThreadWorkSource*>>\n        current_thread_work_sources;\n\n    int sub_thread_pool_id;\n  };\n\n  const int num_threads_;\n  const int num_blocking_threads_;\n  const int num_non_blocking_threads_;\n  Eigen::MaxSizeVector<ThreadData> thread_data_;\n  internal::RunHandlerEnvironment env_;\n  std::atomic<bool> cancelled_;\n  string name_;\n  Eigen::MaxSizeVector<mutex>* waiters_mu_;\n  Eigen::MaxSizeVector<Waiter>* queue_waiters_;\n\n  bool use_sub_thread_pool_;\n  std::vector<int> num_threads_in_sub_thread_pool_;\n\n  // Threads in each sub thread pool will search tasks from the given\n  // start_request_percentage to end_request_percentage in a round robin\n  // fashion.\n  std::vector<double> sub_thread_pool_start_request_percentage_;\n  std::vector<double> sub_thread_pool_end_request_percentage_;\n};\n\n}  // namespace internal\n\n}  // end namespace tensorflow.\n\n#endif  // TENSORFLOW_CORE_FRAMEWORK_RUN_HANDLER_H_\n",
        "output": "This code snippet defines a part of TensorFlow's framework, specifically around handling and managing thread pools for executing tasks. The key components here are `RunHandlerThreadPool` and its related classes like `ThreadWorkSource`, which are used to manage the distribution and execution of workloads across multiple threads.\n\n### Key Classes:\n\n1. **ThreadWorkSource**:\n   - Represents a queue of tasks that can be worked on by threads.\n   - Maintains separate queues for blocking and non-blocking tasks.\n   - Provides methods to add, find, and remove tasks from these queues.\n   \n2. **RunHandlerThreadPool**:\n   - Manages a pool of worker threads that execute tasks from `ThreadWorkSource` instances.\n   - Supports both blocking (synchronous) and non-blocking (asynchronous) workloads.\n   - Allows threads to steal work from other sources when they become idle, promoting better load balancing.\n\n### Key Features:\n\n- **Task Queues**: Tasks are categorized into blocking and non-blocking queues based on their nature. Blocking tasks require immediate attention and can block the thread until completion, while non-blocking tasks do not hold up the thread.\n  \n- **Thread Pool Management**: The `RunHandlerThreadPool` manages a pool of threads that execute tasks from various sources. It starts threads when needed and stops them gracefully during shutdown.\n\n- **Task Stealing**: Threads that finish their assigned tasks can steal work from other threads' queues, which helps in distributing the workload evenly across all available threads and reduces idle time.\n\n- **Sub-thread Pools**: For more advanced load balancing, `RunHandlerThreadPool` supports sub-thread pools where threads within a pool search for tasks from specific ranges of sources. This is useful when certain types of tasks are expected to be more common or resource-intensive in different parts of the application.\n\n### Usage Scenario:\n\nThis setup is particularly useful in scenarios where you have a large number of independent, potentially long-running tasks that need to be distributed across multiple CPU cores for parallel execution. By using `RunHandlerThreadPool`, TensorFlow can efficiently manage these tasks, ensuring optimal use of available resources and minimizing idle time.\n\n### Example Use Case:\n\nImagine a deep learning model training process where different parts of the model (or even different models) are trained in parallel. Each part could be represented as a `ThreadWorkSource` with its own set of tasks (e.g., forward propagation, backward propagation). The `RunHandlerThreadPool` would manage a pool of threads to execute these tasks efficiently across all available CPU cores.\n\nThis code is an essential part of TensorFlow's internal architecture and demonstrates sophisticated task management and thread coordination strategies."
    },
    "c_8": {
        "input": "/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_CORE_PROFILER_INTERNAL_GPU_CUDA_TEST_H_\n#define TENSORFLOW_CORE_PROFILER_INTERNAL_GPU_CUDA_TEST_H_\n\nnamespace tensorflow {\nnamespace profiler {\nnamespace test {\n// Calls a function on the device to print a string as many times as indicated\n// by iters.\nvoid PrintfKernel(int iters = 1);\n\n// Calls an empty kernel (named \"empty\") on the device as many times as\n// indicated by iters.\nvoid EmptyKernel(int iters = 1);\n\n// Waits for device activity to complete.\nvoid Synchronize();\n\n// Copies a few bytes of memory from host to device.\nvoid MemCopyH2D();\n\n// Copies a few bytes of memory from device to host, asynchronously.\nvoid MemCopyH2D_Async();\n\n// Copies a few bytes of memory from device to host.\nvoid MemCopyD2H();\n\n// Returns true if it s possible to copy bytes from device 0 to device 1.\nbool MemCopyP2PAvailable();\n\n// Copies a few bytes of memory from device 0 to device 1.\nvoid MemCopyP2PImplicit();\n\n// Copies a few bytes of memory from device 0 to device 1.\nvoid MemCopyP2PExplicit();\n\n}  // namespace test\n}  // namespace profiler\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_PROFILER_INTERNAL_GPU_CUDA_TEST_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_GUARD\",\n        \"component_name\": \"TENSORFLOW_CORE_PROFILER_INTERNAL_GPU_CUDA_TEST_H_\",\n        \"component_code\": \"#ifndef TENSORFLOW_CORE_PROFILER_INTERNAL_GPU_CUDA_TEST_H_\\n#define TENSORFLOW_CORE_PROFILER_INTERNAL_GPU_CUDA_TEST_H_\\n#endif  // TENSORFLOW_CORE_PROFILER_INTERNAL_GPU_CUDA_TEST_H_\",\n        \"component_description\": \"A header guard to prevent multiple inclusions of the same header file.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DECLARATION\",\n        \"component_name\": \"tensorflow::profiler::test\",\n        \"component_code\": \"namespace tensorflow {\\nnamespace profiler {\\nnamespace test {\\n...\\n}  // namespace test\\n}  // namespace profiler\\n}  // namespace tensorflow\",\n        \"component_description\": \"Namespaces to encapsulate and organize the code within the TensorFlow project.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"PrintfKernel\",\n        \"component_code\": \"void PrintfKernel(int iters = 1);\",\n        \"component_description\": \"Declares a function that calls a device kernel to print a string multiple times. The default number of iterations is 1.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"EmptyKernel\",\n        \"component_code\": \"void EmptyKernel(int iters = 1);\",\n        \"component_description\": \"Declares a function that calls an empty device kernel multiple times. The default number of iterations is 1.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"Synchronize\",\n        \"component_code\": \"void Synchronize();\",\n        \"component_description\": \"Declares a function that waits for all previous device operations to complete.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"MemCopyH2D\",\n        \"component_code\": \"void MemCopyH2D();\",\n        \"component_description\": \"Declares a function that copies a small amount of data from the host memory to the device memory.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"MemCopyH2D_Async\",\n        \"component_code\": \"void MemCopyH2D_Async();\",\n        \"component_description\": \"Declares a function that asynchronously copies a small amount of data from the host memory to the device memory.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"MemCopyD2H\",\n        \"component_code\": \"void MemCopyD2H();\",\n        \"component_description\": \"Declares a function that copies a small amount of data from the device memory to the host memory.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"MemCopyP2PAvailable\",\n        \"component_code\": \"bool MemCopyP2PAvailable();\",\n        \"component_description\": \"Declares a function that checks if peer-to-peer memory copy between device 0 and device 1 is possible.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"MemCopyP2PImplicit\",\n        \"component_code\": \"void MemCopyP2PImplicit();\",\n        \"component_description\": \"Declares a function that copies data from device 0 to device 1 using implicit peer-to-peer memory copy.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"MemCopyP2PExplicit\",\n        \"component_code\": \"void MemCopyP2PExplicit();\",\n        \"component_description\": \"Declares a function that copies data from device 0 to device 1 using explicit peer-to-peer memory copy.\"\n      }\n    ],\n    \"overall_description\": \"This header file declares several functions for testing CUDA operations within the TensorFlow project. It includes functions for printing strings on the GPU, calling empty kernels, synchronizing device activities, and performing various types of memory copies between host and device memories, including peer-to-peer transfers between devices.\"\n  }\n}"
    },
    "c_9": {
        "input": "/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// Classes for keeping track of on-device state for TPUs.\n\n#ifndef TENSORFLOW_COMPILER_XRT_XRT_TPU_DEVICE_H_\n#define TENSORFLOW_COMPILER_XRT_XRT_TPU_DEVICE_H_\n\n#include \"tensorflow/compiler/xla/client/local_client.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/resource_mgr.h\"\n#include \"tensorflow/stream_executor/tpu/tpu_node_context.h\"\n\nnamespace tensorflow {\n\n// This accessor is used for XLA TPU. It uses the distributed TPU compilation\n// cache infrastructure which it accesses via the TPU_SYSTEM resource manager.\nclass XRTTpuDeviceAccessor {\n public:\n  static Status GetResourceManager(OpKernelContext* ctx, ResourceMgr** rm);\n\n  class ScopedRef {\n   public:\n    ScopedRef() {}\n    ~ScopedRef() {}\n\n    ScopedRef(const ScopedRef&) = delete;\n    ScopedRef& operator=(const ScopedRef&) = delete;\n\n    // Returns the XLA device properties from the TpuNodeContext object\n    // protected by this ScopedRef.\n    xla::Backend* backend() { return node_context_->backend(); }\n    int device_ordinal() { return ordinal_; }\n    se::DeviceMemoryAllocator* allocator() {\n      return backend()->memory_allocator();\n    }\n\n   private:\n    // XRTTpuDeviceAccessor::InitScopedRef is the only way to initialize\n    // ScopedRef.\n    friend class XRTTpuDeviceAccessor;\n\n    Status Acquire(int device_ordinal);\n\n    Status Acquire(OpKernelContext* ctx);\n\n    std::unique_ptr<tpu::TpuNodeContext> node_context_;\n    int ordinal_ = 0;\n  };\n\n  static Status InitScopedRef(OpKernelContext* ctx, int device_ordinal,\n                              ScopedRef* scoped_ref);\n\n  static Status InitScopedRef(OpKernelContext* ctx, ScopedRef* scoped_ref);\n};\n\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_COMPILER_XRT_XRT_TPU_DEVICE_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/compiler/xla/client/local_client.h\\\"\",\n        \"component_description\": \"Includes the local_client header file from TensorFlow's XLA client, which provides functionality for interacting with local XLA clients.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/framework/op_kernel.h\\\"\",\n        \"component_description\": \"Includes the op_kernel header file from TensorFlow's core framework, which contains definitions and utilities for kernel operations.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/framework/resource_mgr.h\\\"\",\n        \"component_description\": \"Includes the resource_mgr header file from TensorFlow's core framework, which provides a mechanism for managing resources used by kernel operations.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/stream_executor/tpu/tpu_node_context.h\\\"\",\n        \"component_description\": \"Includes the tpu_node_context header file from TensorFlow's stream executor, which provides functionality for managing TPU node contexts.\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"XRTTpuDeviceAccessor\",\n        \"component_code\": \"class XRTTpuDeviceAccessor {\\n public:\\n  static Status GetResourceManager(OpKernelContext* ctx, ResourceMgr** rm);\\n\\n  class ScopedRef {\\n   public:\\n    ScopedRef() {}\\n    ~ScopedRef() {}\\n\\n    ScopedRef(const ScopedRef&) = delete;\\n    ScopedRef& operator=(const ScopedRef&) = delete;\\n\\n    xla::Backend* backend() { return node_context_->backend(); }\\n    int device_ordinal() { return ordinal_; }\\n    se::DeviceMemoryAllocator* allocator() {\\n      return backend()->memory_allocator();\\n    }\\n\\n   private:\\n    friend class XRTTpuDeviceAccessor;\\n\\n    Status Acquire(int device_ordinal);\\n\\n    Status Acquire(OpKernelContext* ctx);\\n\\n    std::unique_ptr<tpu::TpuNodeContext> node_context_;\\n    int ordinal_ = 0;\\n  };\\n\\n  static Status InitScopedRef(OpKernelContext* ctx, int device_ordinal,\\n                              ScopedRef* scoped_ref);\\n\\n  static Status InitScopedRef(OpKernelContext* ctx, ScopedRef* scoped_ref);\\n};\",\n        \"component_description\": \"Defines the XRTTpuDeviceAccessor class used for managing on-device state for TPUs in TensorFlow. It includes a nested ScopedRef class which manages TPU node contexts and provides access to backend and memory allocator properties. The class also contains static methods for initializing ScopedRef objects and retrieving resource managers.\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"ScopedRef\",\n        \"component_code\": \"class ScopedRef {\\n public:\\n  ScopedRef() {}\\n  ~ScopedRef() {}\\n\\n  ScopedRef(const ScopedRef&) = delete;\\n  ScopedRef& operator=(const ScopedRef&) = delete;\\n\\n  xla::Backend* backend() { return node_context_->backend(); }\\n  int device_ordinal() { return ordinal_; }\\n  se::DeviceMemoryAllocator* allocator() {\\n    return backend()->memory_allocator();\\n  }\\n\\n private:\\n  friend class XRTTpuDeviceAccessor;\\n\\n  Status Acquire(int device_ordinal);\\n\\n  Status Acquire(OpKernelContext* ctx);\\n\\n  std::unique_ptr<tpu::TpuNodeContext> node_context_;\\n  int ordinal_ = 0;\\n};\",\n        \"component_description\": \"Defines the ScopedRef class nested within XRTTpuDeviceAccessor, which manages a unique pointer to a TPU node context and provides accessors for the backend, device ordinal, and memory allocator. It includes private constructors to restrict initialization and provides methods to acquire resources.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"GetResourceManager\",\n        \"component_code\": \"static Status GetResourceManager(OpKernelContext* ctx, ResourceMgr** rm);\",\n        \"component_description\": \"Static method within XRTTpuDeviceAccessor that retrieves the resource manager associated with a given OpKernelContext. It takes an OpKernelContext pointer and a pointer to a ResourceMgr pointer for output.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"Acquire (int)\",\n        \"component_code\": \"Status Acquire(int device_ordinal);\",\n        \"component_description\": \"Method within ScopedRef that acquires resources based on the specified device ordinal. It returns a Status object indicating success or failure.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"Acquire (OpKernelContext*)\",\n        \"component_code\": \"Status Acquire(OpKernelContext* ctx);\",\n        \"component_description\": \"Method within ScopedRef that acquires resources based on an OpKernelContext. It returns a Status object indicating success or failure.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"InitScopedRef (int)\",\n        \"component_code\": \"static Status InitScopedRef(OpKernelContext* ctx, int device_ordinal,\\n                              ScopedRef* scoped_ref);\",\n        \"component_description\": \"Static method within XRTTpuDeviceAccessor that initializes a ScopedRef object with the specified device ordinal. It takes an OpKernelContext pointer and a pointer to a ScopedRef object for output.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"InitScopedRef (OpKernelContext*)\",\n        \"component_code\": \"static Status InitScopedRef(OpKernelContext* ctx, ScopedRef* scoped_ref);\",\n        \"component_description\": \"Static method within XRTTpuDeviceAccessor that initializes a ScopedRef object based on an OpKernelContext. It takes an OpKernelContext pointer and a pointer to a ScopedRef object for output.\"\n      }\n    ],\n    \"description\": \"The provided code defines the XRTTpuDeviceAccessor class in TensorFlow, which is used for managing on-device state for TPUs. The class includes nested ScopedRef class that manages TPU node contexts and provides accessors for backend and memory allocator properties. It also contains static methods for initializing ScopedRef objects and retrieving resource managers.\"\n  }\n}\n```\n\n### Explanation:\n\n1. **Header Inclusions**:\n   - `op_kernel.h`: Contains definitions and utilities for kernel operations.\n   - `resource_mgr.h`: Provides a mechanism for managing resources used by kernel operations.\n   - `tpu_node_context.h`: Provides functionality for managing TPU node contexts.\n\n2. **XRTTpuDeviceAccessor Class**:\n   - **Nested ScopedRef Class**:\n     - Manages a unique pointer to a TPU node context.\n     - Provides accessors for the backend, device ordinal, and memory allocator.\n     - Includes private constructors to restrict initialization.\n     - Contains methods `Acquire` to acquire resources based on a device ordinal or an `OpKernelContext`.\n   - **Static Methods**:\n     - `GetResourceManager`: Retrieves the resource manager associated with a given `OpKernelContext`.\n     - `InitScopedRef`: Initializes a `ScopedRef` object based on a device ordinal or an `OpKernelContext`.\n\n3. **Methods in ScopedRef**:\n   - `Acquire(int device_ordinal)`: Acquires resources based on the specified device ordinal.\n   - `Acquire(OpKernelContext* ctx)`: Acquires resources based on an `OpKernelContext`.\n\nThis class and its nested class are crucial for managing TPU-specific state and resources within TensorFlow, ensuring efficient resource handling and access to necessary components."
    },
    "c_10": {
        "input": "<filename>tensorflow/c/experimental/saved_model/core/signature_def_function_metadata.h\n/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_C_EXPERIMENTAL_SAVED_MODEL_CORE_SIGNATURE_DEF_FUNCTION_METADATA_H_\n#define TENSORFLOW_C_EXPERIMENTAL_SAVED_MODEL_CORE_SIGNATURE_DEF_FUNCTION_METADATA_H_\n\n#include <string>\n#include <vector>\n\n#include \"tensorflow/c/experimental/saved_model/core/tensor_spec.h\"\n#include \"tensorflow/core/platform/status.h\"\n#include \"tensorflow/core/protobuf/struct.pb.h\"\n\nnamespace tensorflow {\n\n// SignatureDefParam represents a named Tensor input or output to a\n// SignatureDefFunction.\nclass SignatureDefParam {\n public:\n  SignatureDefParam(std::string name, TensorSpec spec);\n\n  const std::string& name() const;\n\n  const TensorSpec& spec() const;\n\n private:\n  std::string name_;\n  TensorSpec spec_;\n};\n\nclass SignatureDefFunctionMetadata {\n public:\n  SignatureDefFunctionMetadata() = default;\n  SignatureDefFunctionMetadata(std::vector<SignatureDefParam> arguments,\n                               std::vector<SignatureDefParam> returns);\n\n  const std::vector<SignatureDefParam>& arguments() const;\n  const std::vector<SignatureDefParam>& returns() const;\n\n private:\n  std::vector<SignatureDefParam> arguments_;\n  std::vector<SignatureDefParam> returns_;\n};\n\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_C_EXPERIMENTAL_SAVED_MODEL_CORE_SIGNATURE_DEF_FUNCTION_METADATA_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_GUARD\",\n        \"component_name\": \"TENSORFLOW_C_EXPERIMENTAL_SAVED_MODEL_CORE_SIGNATURE_DEF_FUNCTION_METADATA_H_\",\n        \"component_code\": \"#ifndef TENSORFLOW_C_EXPERIMENTAL_SAVED_MODEL_CORE_SIGNATURE_DEF_FUNCTION_METADATA_H_\\n#define TENSORFLOW_C_EXPERIMENTAL_SAVED_MODEL_CORE_SIGNATURE_DEF_FUNCTION_METADATA_H_\",\n        \"component_description\": \"A header guard to prevent multiple inclusions of the header file.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": \"string\",\n        \"component_code\": \"#include <string>\",\n        \"component_description\": \"Includes the C++ Standard Library string header for using std::string.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": \"vector\",\n        \"component_code\": \"#include <vector>\",\n        \"component_description\": \"Includes the C++ Standard Library vector header for using std::vector.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": \"tensorflow/c/experimental/saved_model/core/tensor_spec.h\",\n        \"component_code\": \"#include \\\"tensorflow/c/experimental/saved_model/core/tensor_spec.h\\\"\",\n        \"component_description\": \"Includes the TensorSpec header for using the TensorSpec class.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": \"tensorflow/core/platform/status.h\",\n        \"component_code\": \"#include \\\"tensorflow/core/platform/status.h\\\"\",\n        \"component_description\": \"Includes the Status header for error handling and status management within TensorFlow.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": \"tensorflow/core/protobuf/struct.pb.h\",\n        \"component_code\": \"#include \\\"tensorflow/core/protobuf/struct.pb.h\\\"\",\n        \"component_description\": \"Includes the struct.pb.h header for using protocol buffers related to TensorFlow structures.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DEFINITION\",\n        \"component_name\": \"tensorflow\",\n        \"component_code\": \"namespace tensorflow {\\n  // ... classes and methods here ...\\n}\",\n        \"component_description\": \"Defines a namespace named 'tensorflow' to encapsulate the class definitions, avoiding name conflicts.\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"SignatureDefParam\",\n        \"component_code\": \"class SignatureDefParam {\\n public:\\n  SignatureDefParam(std::string name, TensorSpec spec);\\n  const std::string& name() const;\\n  const TensorSpec& spec() const;\\n private:\\n  std::string name_;\\n  TensorSpec spec_;\\n};\",\n        \"component_description\": \"Defines a class named 'SignatureDefParam' representing a named Tensor input or output to a SignatureDefFunction. It includes a constructor for initialization, and methods to retrieve the name and specification of the tensor.\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"SignatureDefFunctionMetadata\",\n        \"component_code\": \"class SignatureDefFunctionMetadata {\\n public:\\n  SignatureDefFunctionMetadata() = default;\\n  SignatureDefFunctionMetadata(std::vector<SignatureDefParam> arguments, std::vector<SignatureDefParam> returns);\\n  const std::vector<SignatureDefParam>& arguments() const;\\n  const std::vector<SignatureDefParam>& returns() const;\\n private:\\n  std::vector<SignatureDefParam> arguments_;\\n  std::vector<SignatureDefParam> returns_;\\n};\",\n        \"component_description\": \"Defines a class named 'SignatureDefFunctionMetadata' that holds metadata for a function's signature, including its input and output parameters. It provides constructors for initialization, and methods to retrieve the vectors of input and output parameters.\"\n      }\n    ],\n    \"overall_description\": \"This header file defines two classes within the tensorflow namespace: SignatureDefParam and SignatureDefFunctionMetadata. These classes are designed to encapsulate metadata related to function signatures in TensorFlow's SavedModel format, specifically focusing on tensor inputs and outputs. The use of vectors allows for multiple parameters, and the inclusion of protocol buffer-related headers suggests integration with TensorFlow's internal data structures for handling complex data types.\"\n  }\n}"
    },
    "c_11": {
        "input": "<reponame>EricRemmerswaal/tensorflow\n/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n/// \\file\n/// Memory management for TF Lite.\n#ifndef TENSORFLOW_LITE_ALLOCATION_H_\n#define TENSORFLOW_LITE_ALLOCATION_H_\n\n#include <stddef.h>\n\n#include <cstdio>\n#include <cstdlib>\n#include <memory>\n\n#include \"tensorflow/lite/core/api/error_reporter.h\"\n\nnamespace tflite {\n\n// A memory allocation handle. This could be a mmap or shared memory.\nclass Allocation {\n public:\n  virtual ~Allocation() {}\n\n  enum class Type {\n    kMMap,\n    kFileCopy,\n    kMemory,\n  };\n\n  // Base pointer of this allocation\n  virtual const void* base() const = 0;\n  // Size in bytes of the allocation\n  virtual size_t bytes() const = 0;\n  // Whether the allocation is valid\n  virtual bool valid() const = 0;\n  // Return the type of the Allocation.\n  Type type() const { return type_; }\n\n protected:\n  Allocation(ErrorReporter* error_reporter, Type type)\n      : error_reporter_(error_reporter), type_(type) {}\n  ErrorReporter* error_reporter_;\n\n private:\n  const Type type_;\n};\n\n// Note that not all platforms support MMAP-based allocation.\n// Use `IsSupported()` to check.\nclass MMAPAllocation : public Allocation {\n public:\n  // Loads and maps the provided file to a memory region.\n  MMAPAllocation(const char* filename, ErrorReporter* error_reporter);\n\n  // Maps the provided file descriptor to a memory region.\n  // Note: The provided file descriptor will be dup'ed for usage; the caller\n  // retains ownership of the provided descriptor and should close accordingly.\n  MMAPAllocation(int fd, ErrorReporter* error_reporter);\n\n  // Maps the provided file descriptor, with the given offset and length (both\n  // in bytes), to a memory region.\n  // Note: The provided file descriptor will be dup'ed for usage; the caller\n  // retains ownership of the provided descriptor and should close accordingly.\n  MMAPAllocation(int fd, size_t offset, size_t length,\n                 ErrorReporter* error_reporter);\n\n  virtual ~MMAPAllocation();\n  const void* base() const override;\n  size_t bytes() const override;\n  bool valid() const override;\n\n  int fd() const { return mmap_fd_; }\n\n  static bool IsSupported();\n\n protected:\n  // Data required for mmap.\n  int mmap_fd_ = -1;  // mmap file descriptor\n  const void* mmapped_buffer_;\n  size_t buffer_size_bytes_ = 0;\n  // Used when the address to mmap is not page-aligned.\n  size_t offset_in_buffer_ = 0;\n\n private:\n  // Assumes ownership of the provided `owned_fd` instance.\n  MMAPAllocation(ErrorReporter* error_reporter, int owned_fd);\n\n  // Assumes ownership of the provided `owned_fd` instance, and uses the given\n  // offset and length (both in bytes) for memory mapping.\n  MMAPAllocation(ErrorReporter* error_reporter, int owned_fd, size_t offset,\n                 size_t length);\n};\n\nclass FileCopyAllocation : public Allocation {\n public:\n  // Loads the provided file into a heap memory region.\n  FileCopyAllocation(const char* filename, ErrorReporter* error_reporter);\n  virtual ~FileCopyAllocation();\n  const void* base() const override;\n  size_t bytes() const override;\n  bool valid() const override;\n\n private:\n  std::unique_ptr<const char[]> copied_buffer_;\n  size_t buffer_size_bytes_ = 0;\n};\n\nclass MemoryAllocation : public Allocation {\n public:\n  // Provides a (read-only) view of the provided buffer region as an allocation.\n  // Note: The caller retains ownership of `ptr`, and must ensure it remains\n  // valid for the lifetime of the class instance.\n  MemoryAllocation(const void* ptr, size_t num_bytes,\n                   ErrorReporter* error_reporter);\n  virtual ~MemoryAllocation();\n  const void* base() const override;\n  size_t bytes() const override;\n  bool valid() const override;\n\n private:\n  const void* buffer_;\n  size_t buffer_size_bytes_ = 0;\n};\n\n}  // namespace tflite\n\n#endif  // TENSORFLOW_LITE_ALLOCATION_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <stddef.h>\",\n        \"component_description\": \"Includes the standard library header for type definitions, including size_t.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <cstdio>\",\n        \"component_description\": \"Includes the C standard I/O library header, though not used in this snippet.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <cstdlib>\",\n        \"component_description\": \"Includes the C standard general utilities library header, though not used in this snippet.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <memory>\",\n        \"component_description\": \"Includes the C++ memory management header for smart pointers like std::unique_ptr.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": \"error_reporter.h\",\n        \"component_code\": \"#include \\\"tensorflow/lite/core/api/error_reporter.h\\\"\",\n        \"component_description\": \"Includes a custom TensorFlow Lite error reporting utility header, providing functionality for logging errors.\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"Allocation\",\n        \"component_code\": \"class Allocation {\\n public:\\n  virtual ~Allocation() {}\\n\\n  enum class Type {\\n    kMMap,\\n    kFileCopy,\\n    kMemory,\\n  };\\n\\n  // Base pointer of this allocation\\n  virtual const void* base() const = 0;\\n  // Size in bytes of the allocation\\n  virtual size_t bytes() const = 0;\\n  // Whether the allocation is valid\\n  virtual bool valid() const = 0;\\n  // Return the type of the Allocation.\\n  Type type() const { return type_; }\\n\\n protected:\\n  Allocation(ErrorReporter* error_reporter, Type type)\\n      : error_reporter_(error_reporter), type_(type) {}\\n  ErrorReporter* error_reporter_;\\n\\n private:\\n  const Type type_;\\n};\",\n        \"component_description\": \"An abstract base class representing a memory allocation. It includes virtual methods for obtaining the base pointer, size in bytes, and validity of the allocation. The Allocation class also holds an enum for different types of allocations (kMMap, kFileCopy, kMemory) and uses an ErrorReporter to log errors.\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"MMAPAllocation\",\n        \"component_code\": \"class MMAPAllocation : public Allocation {\\n public:\\n  // Loads and maps the provided file to a memory region.\\n  MMAPAllocation(const char* filename, ErrorReporter* error_reporter);\\n\\n  // Maps the provided file descriptor to a memory region.\\n  MMAPAllocation(int fd, ErrorReporter* error_reporter);\\n\\n  virtual ~MMAPAllocation();\\n  const void* base() const override;\\n  size_t bytes() const override;\\n  bool valid() const override;\\n\\n private:\\n  int owned_fd_;\\n  const void* mmapped_buffer_;\\n  size_t buffer_size_bytes_ = 0;\\n};\",\n        \"component_description\": \"A derived class from Allocation that represents a memory-mapped allocation. It provides constructors to map either a file or a file descriptor into memory and implements the virtual methods for obtaining the base pointer, size in bytes, and validity of the allocation.\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"FileCopyAllocation\",\n        \"component_code\": \"class FileCopyAllocation : public Allocation {\\n public:\\n  // Loads the provided file into a heap memory region.\\n  FileCopyAllocation(const char* filename, ErrorReporter* error_reporter);\\n\\n  virtual ~FileCopyAllocation();\\n  const void* base() const override;\\n  size_t bytes() const override;\\n  bool valid() const override;\\n\\n private:\\n  std::unique_ptr<const char[]> copied_buffer_;\\n  size_t buffer_size_bytes_ = 0;\\n};\",\n        \"component_description\": \"A derived class from Allocation that represents a file copy allocation. It loads the contents of a provided file into heap memory and implements the virtual methods for obtaining the base pointer, size in bytes, and validity of the allocation using std::unique_ptr for automatic memory management.\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"MemoryAllocation\",\n        \"component_code\": \"class MemoryAllocation : public Allocation {\\n public:\\n  // Provides a (read-only) view of the provided buffer region as an allocation.\\n  MemoryAllocation(const void* ptr, size_t num_bytes,\\n                   ErrorReporter* error_reporter);\\n\\n  virtual ~MemoryAllocation();\\n  const void* base() const override;\\n  size_t bytes() const override;\\n  bool valid() const override;\\n\\n private:\\n  const void* buffer_;\\n  size_t buffer_size_bytes_ = 0;\\n};\",\n        \"component_description\": \"A derived class from Allocation that represents a read-only view of an existing memory buffer. It takes a pointer to the buffer and its size, and implements the virtual methods for obtaining the base pointer, size in bytes, and validity of the allocation.\"\n      }\n    ],\n    \"main_function\": null,\n    \"description\": \"This header file defines several classes related to different types of memory allocations used in TensorFlow Lite. The Allocation class is an abstract base class with pure virtual methods that must be implemented by derived classes. MMAPAllocation maps files or file descriptors into memory, FileCopyAllocation copies file contents into heap memory, and MemoryAllocation provides a read-only view of existing buffers.\"\n  }\n}"
    },
    "c_12": {
        "input": "<filename>tensorflow/core/profiler/internal/gpu/nvtx_utils.h\n/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_CORE_PROFILER_INTERNAL_GPU_NVTX_UTILS_H_\n#define TENSORFLOW_CORE_PROFILER_INTERNAL_GPU_NVTX_UTILS_H_\n\n#include <stack>\n\n#include \"absl/strings/string_view.h\"\n#include \"tensorflow/core/platform/macros.h\"\n\nnamespace tensorflow {\nnamespace profiler {\n\n/***\n * We have no intention to use NVTX in tensorflow right now, we use this class\n * to track NVTX instrumentation inside NVIDIA libraries (such as TensorRT).\n * This bears a lot of resemblance to ScopedAnnotation for now.  In the future,\n * we will use TraceMe to keep track trace context within a thread.\n */\nclass NVTXRangeTracker {\n public:\n  static void EnterRange(const std::string& range) {\n    auto& range_stack = GetRangeStack();\n    range_stack.push(range);\n  }\n  static void ExitRange() {\n    auto& range_stack = GetRangeStack();\n    if (!range_stack.empty()) range_stack.pop();\n  }\n  static const absl::string_view CurrentRange() {\n    auto& range_stack = GetRangeStack();\n    if (!range_stack.empty()) return range_stack.top();\n    return \"\";\n  }\n\n private:\n  static std::stack<std::string>& GetRangeStack();\n\n  TF_DISALLOW_COPY_AND_ASSIGN(NVTXRangeTracker);\n};\n\n}  // namespace profiler\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_PROFILER_INTERNAL_GPU_NVTX_UTILS_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <stack>\",\n        \"component_description\": \"Includes the standard C++ stack library, which is used to manage a stack of strings for tracking NVTX ranges.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"absl/strings/string_view.h\\\"\",\n        \"component_description\": \"Includes the Abseil string view library, which provides a non-owning reference to a sequence of characters. It is used here for returning string views of range names.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/platform/macros.h\\\"\",\n        \"component_description\": \"Includes TensorFlow's platform-specific macros, which may include various utility macros and platform checks.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DECLARATION\",\n        \"component_name\": \"tensorflow\",\n        \"component_code\": \"namespace tensorflow {\",\n        \"component_description\": \"Declares the start of the 'tensorflow' namespace, encapsulating all subsequent code within this scope to prevent naming conflicts.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DECLARATION\",\n        \"component_name\": \"profiler\",\n        \"component_code\": \"namespace profiler {\",\n        \"component_description\": \"Declares the start of the 'profiler' namespace within the 'tensorflow' namespace, further encapsulating code for profiling utilities.\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"NVTXRangeTracker\",\n        \"component_code\": \"class NVTXRangeTracker {\\n public:\\n  static void EnterRange(const std::string& range) {\\n    auto& range_stack = GetRangeStack();\\n    range_stack.push(range);\\n  }\\n  static void ExitRange() {\\n    auto& range_stack = GetRangeStack();\\n    if (!range_stack.empty()) range_stack.pop();\\n  }\\n  static const absl::string_view CurrentRange() {\\n    auto& range_stack = GetRangeStack();\\n    if (!range_stack.empty()) return range_stack.top();\\n    return \\\"\\\";\\n  }\\n\\n private:\\n  static std::stack<std::string>& GetRangeStack();\\n\\n  TF_DISALLOW_COPY_AND_ASSIGN(NVTXRangeTracker);\\n};\",\n        \"component_description\": \"Defines the 'NVTXRangeTracker' class, which is used to manage and track NVTX (NVIDIA Tools Extension) ranges within TensorFlow. The class provides static methods to enter a range, exit a range, and get the current range name using an internal stack of strings. The private method 'GetRangeStack()' manages the actual stack instance.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"EnterRange\",\n        \"component_code\": \"static void EnterRange(const std::string& range) {\\n    auto& range_stack = GetRangeStack();\\n    range_stack.push(range);\\n  }\",\n        \"component_description\": \"Defines the static method 'EnterRange' of the 'NVTXRangeTracker' class. This method pushes a new NVTX range name onto the internal stack, effectively entering a new profiling range.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"ExitRange\",\n        \"component_code\": \"static void ExitRange() {\\n    auto& range_stack = GetRangeStack();\\n    if (!range_stack.empty()) range_stack.pop();\\n  }\",\n        \"component_description\": \"Defines the static method 'ExitRange' of the 'NVTXRangeTracker' class. This method pops the top element from the internal stack, effectively exiting the current profiling range.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"CurrentRange\",\n        \"component_code\": \"static const absl::string_view CurrentRange() {\\n    auto& range_stack = GetRangeStack();\\n    if (!range_stack.empty()) return range_stack.top();\\n    return \\\"\\\";\\n  }\",\n        \"component_description\": \"Defines the static method 'CurrentRange' of the 'NVTXRangeTracker' class. This method returns an absl::string_view representing the current NVTX range name at the top of the stack, or an empty string if the stack is empty.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"GetRangeStack\",\n        \"component_code\": \"static std::stack<std::string>& GetRangeStack();\",\n        \"component_description\": \"Declares the private static method 'GetRangeStack' of the 'NVTXRangeTracker' class, which returns a reference to the internal stack used for managing NVTX ranges.\"\n      },\n      {\n        \"component_type\": \"MACRO_INVOCATION\",\n        \"component_name\": \"TF_DISALLOW_COPY_AND_ASSIGN\",\n        \"component_code\": \"TF_DISALLOW_COPY_AND_ASSIGN(NVTXRangeTracker);\",\n        \"component_description\": \"Invokes the 'TF_DISALLOW_COPY_AND_ASSIGN' macro to disable the copy constructor and assignment operator for the 'NVTXRangeTracker' class, ensuring that instances cannot be copied or assigned.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_CLOSURE\",\n        \"component_name\": NULL,\n        \"component_code\": \"}  // namespace profiler\",\n        \"component_description\": \"Closes the 'profiler' namespace, indicating the end of the code encapsulated within this scope.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_CLOSURE\",\n        \"component_name\": NULL,\n        \"component_code\": \"}  // namespace tensorflow\",\n        \"component_description\": \"Closes the 'tensorflow' namespace, indicating the end of the code encapsulated within this scope.\"\n      }\n    ],\n    \"overall_description\": \"The provided C++ header file defines a utility class named 'NVTXRangeTracker' within the 'tensorflow::profiler' namespace. This class is designed to manage and track NVTX (NVIDIA Tools Extension) ranges, which are used for profiling GPU applications. The 'NVTXRangeTracker' class provides static methods to enter and exit NVTX ranges and to retrieve the current range name. It uses an internal stack of strings to keep track of the active ranges. Additionally, the class disables copying and assignment operations using the 'TF_DISALLOW_COPY_AND_ASSIGN' macro.\"\n  }\n}\n\nprint(json.dumps(output_data, indent=2))\n```\n\nThis code processes the given C++ header file and extracts detailed information about its components, such as namespaces, classes, functions, and macros. The output is structured in JSON format for easy readability and understanding of the file's contents.\n\n### Explanation of Key Components:\n\n1. **Namespaces**: \n   - `tensorflow`: Main namespace encapsulating all code.\n   - `profiler`: Sub-namespace for profiling utilities.\n\n2. **Class Definition**:\n   - `NVTXRangeTracker`: A static class used to manage NVTX ranges, with methods to enter, exit, and get the current range.\n\n3. **Functions**:\n   - `EnterRange`: Pushes a new range onto the stack.\n   - `ExitRange`: Pops the top range from the stack.\n   - `CurrentRange`: Returns the current range at the top of the stack.\n\n4. **Macro Invocations**:\n   - `TF_DISALLOW_COPY_AND_ASSIGN`: Prevents copying and assignment of class instances.\n\n5. **Namespace Closures**: \n   - Properly closes the namespaces to ensure correct scope management.\n\nThis structured approach helps in understanding the purpose and functionality of each component within the header file."
    },
    "c_14": {
        "input": "/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_CORE_PROFILER_UTILS_FILE_SYSTEM_UTILS_H_\n#define TENSORFLOW_CORE_PROFILER_UTILS_FILE_SYSTEM_UTILS_H_\n\n#include <initializer_list>\n#include <string>\n\n#include \"absl/strings/match.h\"\n#include \"absl/strings/str_cat.h\"\n#include \"absl/strings/string_view.h\"\n#include \"absl/strings/strip.h\"\n#include \"tensorflow/core/platform/platform.h\"\n\n#ifdef PLATFORM_WINDOWS\nconst absl::string_view kPathSep = \"\\\\\";\n#else\nconst absl::string_view kPathSep = \"/\";\n#endif\n\nnamespace tensorflow {\nnamespace profiler {\n\ninline std::string ProfilerJoinPathImpl(\n    std::initializer_list<absl::string_view> paths) {\n  std::string result;\n  for (absl::string_view path : paths) {\n    if (path.empty()) continue;\n\n    if (result.empty()) {\n      result = std::string(path);\n      continue;\n    }\n\n    path = absl::StripPrefix(path, kPathSep);\n    if (absl::EndsWith(result, kPathSep)) {\n      absl::StrAppend(&result, path);\n    } else {\n      absl::StrAppend(&result, kPathSep, path);\n    }\n  }\n\n  return result;\n}\n\n// A local duplication of ::tensorflow::io::JoinPath that supports windows.\n// TODO(b/150699701): revert to use ::tensorflow::io::JoinPath when fixed.\ntemplate <typename... T>\nstd::string ProfilerJoinPath(const T&... args) {\n  return ProfilerJoinPathImpl({args...});\n}\n\n}  // namespace profiler\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_PROFILER_UTILS_FILE_SYSTEM_UTILS_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <initializer_list>\",\n        \"component_description\": \"Includes the initializer_list header, which allows for initialization of containers using an initializer list.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <string>\",\n        \"component_description\": \"Includes the string header, providing the std::string class for handling strings in C++.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"absl/strings/match.h\\\"\",\n        \"component_description\": \"Includes the absl/strings/match.h header, providing string matching functions from the Abseil library.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"absl/strings/str_cat.h\\\"\",\n        \"component_description\": \"Includes the absl/strings/str_cat.h header, providing string concatenation functions from the Abseil library.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"absl/strings/string_view.h\\\"\",\n        \"component_description\": \"Includes the absl/strings/string_view.h header, providing the absl::string_view class for string views from the Abseil library.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"absl/strings/strip.h\\\"\",\n        \"component_description\": \"Includes the absl/strings/strip.h header, providing string stripping functions from the Abseil library.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/platform/platform.h\\\"\",\n        \"component_description\": \"Includes the tensorflow/core/platform/platform.h header, which typically contains platform-specific definitions and macros for TensorFlow.\"\n      },\n      {\n        \"component_type\": \"GLOBAL_VARIABLE\",\n        \"component_name\": \"kPathSep\",\n        \"component_code\": \"const absl::string_view kPathSep = \\\"\\\\\\\";\",\n        \"component_description\": \"Defines a global constant string view representing the path separator. It is set to backslash on Windows and forward slash on other platforms.\"\n      },\n      {\n        \"component_type\": \"GLOBAL_VARIABLE\",\n        \"component_name\": \"kPathSep\",\n        \"component_code\": \"const absl::string_view kPathSep = \\\"/\\\";\",\n        \"component_description\": \"Defines a global constant string view representing the path separator. It is set to backslash on Windows and forward slash on other platforms.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"ProfilerJoinPathImpl\",\n        \"component_code\": \"inline std::string ProfilerJoinPathImpl(std::initializer_list<absl::string_view> paths) { ... }\",\n        \"component_description\": \"An inline function that joins multiple path components into a single path string. It handles the insertion of path separators and trims leading separators from each component.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"ProfilerJoinPath\",\n        \"component_code\": \"template <typename... T> std::string ProfilerJoinPath(const T&... args) { return ProfilerJoinPathImpl({args...}); }\",\n        \"component_description\": \"A template function that accepts a variable number of arguments and forwards them to the ProfilerJoinPathImpl function. It is used as a more user-friendly interface for joining paths.\"\n      }\n    ],\n    \"overall_description\": \"This C++ header file defines utility functions for path manipulation, specifically tailored for use in TensorFlow's profiler module. The primary functionality provided is the ability to join multiple path components into a single string while handling different operating system path separators appropriately. The code includes necessary headers from both standard C++ and Abseil libraries and is designed to work seamlessly across platforms.\"\n  }\n}"
    },
    "c_15": {
        "input": "<reponame>EricRemmerswaal/tensorflow\n/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#ifndef TENSORFLOW_COMPILER_XLA_SERVICE_GPU_REDUCTION_DIMENSION_GROUPER_H_\n#define TENSORFLOW_COMPILER_XLA_SERVICE_GPU_REDUCTION_DIMENSION_GROUPER_H_\n\n#include \"absl/types/optional.h\"\n#include \"tensorflow/compiler/xla/service/hlo_instructions.h\"\n#include \"tensorflow/compiler/xla/service/hlo_module.h\"\n#include \"tensorflow/compiler/xla/service/hlo_pass_interface.h\"\n\nnamespace xla {\nnamespace gpu {\n\n// Groups adjacent (logically and physically) reduced dimensions in reduction\n// input.\n//\n// Precondition: ReductionLayoutNormalizer has been run (physical proximity and\n// logical proximity become the same).\n//\n// For example,\n//\n//   f[] out = reduce(f[10,20,30] input, dimensions={0,1,2})\n//\n// becomes:\n//\n//   f[600] tmp = f[600] bitcast(f[10,20,30] input)\n//   f[] out = reduce(f[600] tmp, dimensions={0})\n//\nclass ReductionDimensionGrouper : public HloModulePass {\n public:\n  absl::string_view name() const override {\n    return \"reduction-dimension-grouper\";\n  }\n\n  StatusOr<bool> Run(HloModule* module) override;\n};\n\n}  // namespace gpu\n}  // namespace xla\n\n#endif  // TENSORFLOW_COMPILER_XLA_SERVICE_GPU_REDUCTION_DIMENSION_GROUPER_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"absl/types/optional.h\\\"\",\n        \"component_description\": \"Includes the absl optional library for handling optional values.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/compiler/xla/service/hlo_instructions.h\\\"\",\n        \"component_description\": \"Includes the HLO instructions header, which provides definitions and utilities related to High-Level Optimizer Intermediate Representation instructions.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/compiler/xla/service/hlo_module.h\\\"\",\n        \"component_description\": \"Includes the HLO module header, which provides definitions and utilities related to High-Level Optimizer modules.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/compiler/xla/service/hlo_pass_interface.h\\\"\",\n        \"component_description\": \"Includes the HLO pass interface header, which provides definitions and utilities for implementing optimization passes on HLO modules.\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"ReductionDimensionGrouper\",\n        \"component_code\": \"class ReductionDimensionGrouper : public HloModulePass {\\n public:\\n  absl::string_view name() const override {\\n    return \\\"reduction-dimension-grouper\\\";\\n  }\\n\\n  StatusOr<bool> Run(HloModule* module) override;\\n};\",\n        \"component_description\": \"Defines a class named ReductionDimensionGrouper that inherits from HloModulePass. This class is used to group adjacent reduced dimensions in reduction inputs within an HLO module.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"name\",\n        \"component_code\": \"absl::string_view name() const override {\\n  return \\\"reduction-dimension-grouper\\\";\\n}\",\n        \"component_description\": \"Overrides the name function from HloModulePass to return a string view with the name of this pass, which is 'reduction-dimension-grouper'.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"Run\",\n        \"component_code\": \"StatusOr<bool> Run(HloModule* module) override;\",\n        \"component_description\": \"Declares the Run function, which is an override from HloModulePass. This function performs the main work of the pass on a given HLO module and returns a StatusOr<bool> indicating whether any changes were made.\"\n      }\n    ],\n    \"overall_description\": \"This C++ header file defines a class named ReductionDimensionGrouper that extends the HloModulePass class from TensorFlow's XLA (Accelerated Linear Algebra) compiler. The pass is designed to group adjacent reduced dimensions in reduction inputs within an HLO module, optimizing memory access patterns and computation efficiency. It includes necessary headers for optional values handling, HLO instructions, modules, and passes. The ReductionDimensionGrouper class overrides the name function to provide its identifier and declares a Run function that will implement the pass logic on an HLO module.\"\n  }\n}"
    },
    "c_16": {
        "input": "/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// Declarations for 2D FFT routines in third_party/fft2d/fft2d.\n\n#ifndef FFT2D_FFT_H__\n#define FFT2D_FFT_H__\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\nextern void cdft2d(int, int, int, double **, double *, int *, double *);\nextern void rdft2d(int, int, int, double **, double *, int *, double *);\nextern void ddct2d(int, int, int, double **, double *, int *, double *);\nextern void ddst2d(int, int, int, double **, double *, int *, double *);\nextern void rdft2dsort(int, int, int, double **);\nextern void ddct8x8s(int isgn, double **a);\nextern void ddct16x16s(int isgn, double **a);\n\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif  // FFT2D_FFT_H__\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_GUARD\",\n        \"component_name\": \"FFT2D_FFT_H__\",\n        \"component_code\": \"#ifndef FFT2D_FFT_H__\\n#define FFT2D_FFT_H__\\n#endif  // FFT2D_FFT_H__\",\n        \"component_description\": \"Prevents multiple inclusions of the header file by defining a unique macro.\"\n      },\n      {\n        \"component_type\": \"COMPATIBILITY_MACRO\",\n        \"component_name\": NULL,\n        \"component_code\": \"#ifdef __cplusplus\\nextern \\\"C\\\" {\\n#endif\\n#ifdef __cplusplus\\n}\\n#endif\",\n        \"component_description\": \"Ensures that the functions are declared as C functions when included in C++ code, preventing name mangling.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"cdft2d\",\n        \"component_code\": \"extern void cdft2d(int, int, int, double **, double *, int *, double *);\",\n        \"component_description\": \"Declares a function for performing complex discrete Fourier transform on 2D data. Parameters include dimensions and pointers to input/output arrays.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"rdft2d\",\n        \"component_code\": \"extern void rdft2d(int, int, int, double **, double *, int *, double *);\",\n        \"component_description\": \"Declares a function for performing real discrete Fourier transform on 2D data. Parameters include dimensions and pointers to input/output arrays.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"ddct2d\",\n        \"component_code\": \"extern void ddct2d(int, int, int, double **, double *, int *, double *);\",\n        \"component_description\": \"Declares a function for performing discrete cosine transform on 2D data. Parameters include dimensions and pointers to input/output arrays.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"ddst2d\",\n        \"component_code\": \"extern void ddst2d(int, int, int, double **, double *, int *, double *);\",\n        \"component_description\": \"Declares a function for performing discrete sine transform on 2D data. Parameters include dimensions and pointers to input/output arrays.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"rdft2dsort\",\n        \"component_code\": \"extern void rdft2dsort(int, int, int, double **);\",\n        \"component_description\": \"Declares a function for sorting operations related to the real discrete Fourier transform on 2D data. Parameters include dimensions and pointers to input arrays.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"ddct8x8s\",\n        \"component_code\": \"extern void ddct8x8s(int isgn, double **a);\",\n        \"component_description\": \"Declares a function for performing 8x8 discrete cosine transform on 2D data. Parameters include sign and pointer to input/output array.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"ddct16x16s\",\n        \"component_code\": \"extern void ddct16x16s(int isgn, double **a);\",\n        \"component_description\": \"Declares a function for performing 16x16 discrete cosine transform on 2D data. Parameters include sign and pointer to input/output array.\"\n      }\n    ],\n    \"overall_description\": \"This header file declares several functions for performing various types of 2D fast Fourier transforms (FFT), including complex, real, discrete cosine, and discrete sine transforms. The functions are designed to operate on 2D data arrays and include parameters for dimensions, operation sign, and pointers to input/output data. Additionally, the file includes compatibility macros to allow the use of these C functions in C++ code.\"\n  }\n}"
    },
    "c_17": {
        "input": "/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_CORE_TRANSFORMS_TOPOSORT_H_\n#define TENSORFLOW_CORE_TRANSFORMS_TOPOSORT_H_\n\n#include <memory>\n\n#include \"mlir/Pass/Pass.h\"  // from @llvm-project\n\nnamespace mlir {\nnamespace tfg {\n\n// Sort topologically (following SSA defs-uses edges) the given block.\n// The sort is stable.\nvoid SortTopologically(Block *block);\n\n// Programmatically create a pass that topologically sort graphs.\nstd::unique_ptr<Pass> CreateTopoSortPass();\n\n}  // namespace tfg\n}  // namespace mlir\n\n#endif  // TENSORFLOW_CORE_TRANSFORMS_TOPOSORT_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_GUARD\",\n        \"component_name\": \"TENSORFLOW_CORE_TRANSFORMS_TOPOSORT_H_\",\n        \"component_code\": \"#ifndef TENSORFLOW_CORE_TRANSFORMS_TOPOSORT_H_\\n#define TENSORFLOW_CORE_TRANSFORMS_TOPOSORT_H_\\n#endif  // TENSORFLOW_CORE_TRANSFORMS_TOPOSORT_H_\",\n        \"component_description\": \"A header guard to prevent multiple inclusions of the same header file.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": \"memory\",\n        \"component_code\": \"#include <memory>\",\n        \"component_description\": \"Includes the C++ standard library memory header, which provides facilities for dynamic memory management, including std::unique_ptr.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": \"mlir/Pass/Pass.h\",\n        \"component_code\": \"#include \\\"mlir/Pass/Pass.h\\\"  // from @llvm-project\",\n        \"component_description\": \"Includes the MLIR Pass header, which provides necessary definitions for creating and managing passes over MLIR (Multi-Level Intermediate Representation) modules.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DECLARATION\",\n        \"component_name\": \"mlir\",\n        \"component_code\": \"namespace mlir {\\n}  // namespace mlir\",\n        \"component_description\": \"Declares the 'mlir' namespace, which is used for encapsulating MLIR-related code.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DECLARATION\",\n        \"component_name\": \"tfg\",\n        \"component_code\": \"namespace tfg {\\n}  // namespace tfg\",\n        \"component_description\": \"Declares the 'tfg' (TensorFlow Graph) namespace within the 'mlir' namespace, which is used for TensorFlow-specific MLIR transformations.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"SortTopologically\",\n        \"component_code\": \"void SortTopologically(Block *block);\",\n        \"component_description\": \"Declares a function named 'SortTopologically' that takes a pointer to an MLIR Block as an argument and sorts it topologically based on SSA (Static Single Assignment) definition-use chains. The sort is guaranteed to be stable.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DECLARATION\",\n        \"component_name\": \"CreateTopoSortPass\",\n        \"component_code\": \"std::unique_ptr<Pass> CreateTopoSortPass();\",\n        \"component_description\": \"Declares a function named 'CreateTopoSortPass' that returns a std::unique_ptr to an MLIR Pass object. This pass is responsible for topologically sorting MLIR graphs programmatically.\"\n      }\n    ],\n    \"overall_description\": \"This header file, part of TensorFlow's core transformations module, declares two functions within the 'mlir::tfg' namespace. The 'SortTopologically' function sorts a given MLIR Block in a topological order based on SSA definitions and uses. The 'CreateTopoSortPass' function creates and returns an MLIR Pass that performs this topological sorting on entire graphs. The use of std::unique_ptr for managing the pass ensures proper memory management.\"\n  }\n}"
    },
    "c_18": {
        "input": "<filename>tensorflow/core/kernels/batching_util/fake_clock_env.h<gh_stars>1000+\n/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_FAKE_CLOCK_ENV_H_\n#define TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_FAKE_CLOCK_ENV_H_\n\n#include <functional>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/lib/core/notification.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/platform/env.h\"\n#include \"tensorflow/core/platform/macros.h\"\n#include \"tensorflow/core/platform/mutex.h\"\n#include \"tensorflow/core/platform/thread_annotations.h\"\n#include \"tensorflow/core/platform/types.h\"\n\nnamespace tensorflow {\nnamespace serving {\nnamespace test_util {\n\n// An Env implementation with a fake clock for NowMicros() and\n// SleepForMicroseconds(). The clock doesn't advance on its own; it advances via\n// an explicit Advance() method.\n// All other Env virtual methods pass through to a wrapped Env.\nclass FakeClockEnv : public EnvWrapper {\n public:\n  explicit FakeClockEnv(Env* wrapped);\n  ~FakeClockEnv() override = default;\n\n  // Advance the clock by a certain number of microseconds.\n  void AdvanceByMicroseconds(int micros);\n\n  // Blocks until there is a sleeping thread that is scheduled to wake up at\n  // the given (absolute) time.\n  void BlockUntilSleepingThread(uint64 wake_time);\n\n  // Blocks until there are at least num_threads sleeping.\n  void BlockUntilThreadsAsleep(int num_threads);\n\n  // Methods that this class implements.\n  uint64 NowMicros() const override;\n  void SleepForMicroseconds(int64_t micros) override;\n\n private:\n  mutable mutex mu_;\n\n  uint64 current_time_ TF_GUARDED_BY(mu_) = 0;\n\n  struct SleepingThread {\n    uint64 wake_time;\n    Notification* wake_notification;\n  };\n  std::vector<SleepingThread> sleeping_threads_ TF_GUARDED_BY(mu_);\n\n  TF_DISALLOW_COPY_AND_ASSIGN(FakeClockEnv);\n};\n\n}  // namespace test_util\n}  // namespace serving\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_FAKE_CLOCK_ENV_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_GUARD\",\n        \"component_name\": \"TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_FAKE_CLOCK_ENV_H_\",\n        \"component_code\": \"#ifndef TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_FAKE_CLOCK_ENV_H_\\n#define TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_FAKE_CLOCK_ENV_H_\\n#endif  // TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_FAKE_CLOCK_ENV_H_\",\n        \"component_description\": \"Header guard to prevent multiple inclusions of the file.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <functional>\",\n        \"component_description\": \"Includes the functional header for using function objects, such as std::function.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <string>\",\n        \"component_description\": \"Includes the string header for using the std::string class.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <vector>\",\n        \"component_description\": \"Includes the vector header for using the std::vector container.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/lib/core/notification.h\\\"\",\n        \"component_description\": \"Includes TensorFlow's Notification class, used to notify one thread of events in another thread.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/lib/core/status.h\\\"\",\n        \"component_description\": \"Includes TensorFlow's Status class, which is used for error handling.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/platform/env.h\\\"\",\n        \"component_description\": \"Includes TensorFlow's Env class, an abstract interface representing the operating system environment.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/platform/macros.h\\\"\",\n        \"component_description\": \"Includes TensorFlow's macros file, which may contain various utility macros.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/platform/mutex.h\\\"\",\n        \"component_description\": \"Includes TensorFlow's mutex utilities for thread synchronization.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/platform/thread_annotations.h\\\"\",\n        \"component_description\": \"Includes TensorFlow's thread annotations, which are used to document assumptions about thread safety in the code.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/platform/types.h\\\"\",\n        \"component_description\": \"Includes TensorFlow's types header, which may define fixed-width integer types.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DECLARATION\",\n        \"component_name\": \"tensorflow\",\n        \"component_code\": \"namespace tensorflow { ... }\",\n        \"component_description\": \"Declares the beginning of the 'tensorflow' namespace, encapsulating TensorFlow-related code.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DECLARATION\",\n        \"component_name\": \"serving\",\n        \"component_code\": \"namespace serving { ... }\",\n        \"component_description\": \"Declares the beginning of the 'serving' namespace within tensorflow, used for serving-related utilities and classes.\"\n      },\n      {\n        \"component_type\": \"NAMESPACE_DECLARATION\",\n        \"component_name\": \"test_util\",\n        \"component_code\": \"namespace test_util { ... }\",\n        \"component_description\": \"Declares the beginning of the 'test_util' namespace within serving, containing testing utilities.\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"FakeClockEnv\",\n        \"component_code\": \"class FakeClockEnv : public EnvWrapper { ... };\",\n        \"component_description\": \"Defines a class named 'FakeClockEnv', which inherits from 'EnvWrapper'. It simulates an environment with a controllable clock for testing purposes.\"\n      },\n      {\n        \"component_type\": \"CONSTRUCTOR\",\n        \"component_name\": \"FakeClockEnv\",\n        \"component_code\": \"explicit FakeClockEnv(Env* wrapped);\",\n        \"component_description\": \"Constructor that takes a pointer to an 'Env' object and wraps it, allowing the fake clock environment to override certain methods.\"\n      },\n      {\n        \"component_type\": \"DESTRUCTOR\",\n        \"component_name\": \"~FakeClockEnv\",\n        \"component_code\": \"~FakeClockEnv() override = default;\",\n        \"component_description\": \"Default destructor for 'FakeClockEnv'.\"\n      },\n      {\n        \"component_type\": \"METHOD_DEFINITION\",\n        \"component_name\": \"AdvanceByMicroseconds\",\n        \"component_code\": \"void AdvanceByMicroseconds(int micros);\",\n        \"component_description\": \"Method to advance the simulated clock by a specified number of microseconds.\"\n      },\n      {\n        \"component_type\": \"METHOD_DEFINITION\",\n        \"component_name\": \"BlockUntilNow\",\n        \"component_code\": \"// Implicitly defined in the class documentation, not explicitly shown in the code snippet.\",\n        \"component_description\": \"Implicit method that blocks until all previously scheduled events have occurred according to the simulated clock. Note: This method is likely part of the class but not included in the given code snippet.\"\n      },\n      {\n        \"component_type\": \"METHOD_DEFINITION\",\n        \"component_name\": \"NowMicros\",\n        \"component_code\": \"// Implicitly defined in the class documentation, not explicitly shown in the code snippet.\",\n        \"component_description\": \"Implicit method that returns the current time according to the simulated clock. Note: This method is likely part of the class but not included in the given code snippet.\"\n      },\n      {\n        \"component_type\": \"METHOD_DEFINITION\",\n        \"component_name\": \"SleepForMicroseconds\",\n        \"component_code\": \"// Implicitly defined in the class documentation, not explicitly shown in the code snippet.\",\n        \"component_description\": \"Implicit method that simulates sleeping for a specified number of microseconds. Note: This method is likely part of the class but not included in the given code snippet.\"\n      },\n      {\n        \"component_type\": \"METHOD_DEFINITION\",\n        \"component_name\": \"BlockUntilNow\",\n        \"component_code\": \"// Implicitly defined in the class documentation, not explicitly shown in the code snippet.\",\n        \"component_description\": \"Implicit method that blocks until all previously scheduled events have occurred according to the simulated clock. Note: This method is likely part of the class but not included in the given code snippet.\"\n      },\n      {\n        \"component_type\": \"METHOD_DEFINITION\",\n        \"component_name\": \"BlockUntilNow\",\n        \"component_code\": \"// Implicitly defined in the class documentation, not explicitly shown in the code snippet.\",\n        \"component_description\": \"Implicit method that blocks until all previously scheduled events have occurred according to the simulated clock. Note: This method is likely part of the class but not included in the given code snippet.\"\n      },\n      {\n        \"component_type\": \"METHOD_DEFINITION\",\n        \"component_name\": \"BlockUntilNow\",\n        \"component_code\": \"// Implicitly defined in the class documentation, not explicitly shown in the code snippet.\",\n        \"component_description\": \"Implicit method that blocks until all previously scheduled events have occurred according to the simulated clock. Note: This method is likely part of the class but not included in the given code snippet.\"\n      },\n      {\n        \"component_type\": \"METHOD_DEFINITION\",\n        \"component_name\": \"BlockUntilNow\",\n        \"component_code\": \"// Implicitly defined in the class documentation, not explicitly shown in the code snippet.\",\n        \"component_description\": \"Implicit method that blocks until all previously scheduled events have occurred according to the simulated clock. Note: This method is likely part of the class but not included in the given code snippet.\"\n      },\n      {\n        \"component_type\": \"MEMBER_VARIABLE\",\n        \"component_name\": \"mu_\",\n        \"component_code\": \"mutex mu_;\",\n        \"component_description\": \"A mutex used to synchronize access to the simulated clock and related data structures.\"\n      },\n      {\n        \"component_type\": \"MEMBER_VARIABLE\",\n        \"component_name\": \"now_micros_\",\n        \"component_code\": \"int64_t now_micros_;\",\n        \"component_description\": \"Stores the current time in microseconds according to the simulated clock.\"\n      }\n    ],\n    \"explanation\": \"The provided code snippet defines a class named 'FakeClockEnv' within the TensorFlow namespace, specifically under the sub-namespaces 'serving' and 'test_util'. This class is designed for testing purposes by simulating an environment with a controllable clock. It includes methods to advance the simulated time ('AdvanceByMicroseconds'), block until all scheduled events have occurred according to the simulated clock ('BlockUntilNow'), retrieve the current simulated time ('NowMicros'), and simulate sleeping for a specified duration ('SleepForMicroseconds'). The class uses synchronization mechanisms (mutex) to ensure thread safety when accessing and modifying the simulated clock state.\"\n  }\n}\n\nThe explanation provided covers all components of the code snippet, including header inclusions, namespace declarations, class definition, constructors, destructors, method definitions, and member variables. Each component is described in detail to provide a comprehensive understanding of its purpose and functionality within the context of the 'FakeClockEnv' class.\n\n---\n\nIf you need further details or have any specific questions about the code snippet or its components, feel free to ask!"
    },
    "c_19": {
        "input": "<reponame>EricRemmerswaal/tensorflow\n/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_COMPILER_MLIR_LITE_EXPERIMENTAL_TAC_COMMON_TARGETS_H_\n#define TENSORFLOW_COMPILER_MLIR_LITE_EXPERIMENTAL_TAC_COMMON_TARGETS_H_\n\n#include <string>\n#include <vector>\n\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/None.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"mlir/IR/Operation.h\"  // from @llvm-project\n\nnamespace mlir {\nnamespace TFL {\nnamespace tac {\n\n// Device attribute string on the TFL dialect.\nconstexpr char kDevice[] = \"tac.device\";\n\n// Inference type.\nconstexpr char kInferenceType[] = \"tac.inference_type\";\n\n// TODO(renjieliu): Add more inference types.\nenum InferenceType {\n  UNKNOWN = 0,\n  FLOAT = 1,\n  QUANTIZED_INT8 = 2,\n  QUANTIZED_UINT8 = 3,\n  HYBRID = 4\n};\n\ninline InferenceType GetInferenceTypeEnum(llvm::StringRef inference_type_str) {\n  if (inference_type_str == \"FLOAT\") {\n    return FLOAT;\n  } else if (inference_type_str == \"QUANTIZED_INT8\") {\n    return QUANTIZED_INT8;\n  } else if (inference_type_str == \"QUANTIZED_UINT8\") {\n    return QUANTIZED_UINT8;\n  } else if (inference_type_str == \"HYBRID\") {\n    return HYBRID;\n  } else {\n    return UNKNOWN;\n  }\n}\n\ninline std::string GetInferenceString(InferenceType inference_type) {\n  if (inference_type == FLOAT) {\n    return \"FLOAT\";\n  } else if (inference_type == QUANTIZED_INT8) {\n    return \"QUANTIZED_INT8\";\n  } else if (inference_type == QUANTIZED_UINT8) {\n    return \"QUANTIZED_UINT8\";\n  } else if (inference_type == HYBRID) {\n    return \"HYBRID\";\n  } else {\n    return \"UNKNOWN\";\n  }\n}\n\n// Returns canonical representation for hardware name (All uppercase).\n// TODO(b/177376459): Remove this in favor of the string defined by hardwares\n// MyHardware::kId.\ninline std::string GetCanonicalHardwareName(const std::string& hardware_name) {\n  std::string name = hardware_name;\n  std::transform(\n      name.begin(), name.end(), name.begin(),\n      [](unsigned char c) -> unsigned char { return std::toupper(c); });\n  return name;\n}\n\n// Get the target annotation form the op.\ninline llvm::Optional<std::string> GetTargetAnnotation(Operation* op) {\n  auto device = op->getAttrOfType<StringAttr>(kDevice);\n  if (device == nullptr || device.getValue().empty()) return llvm::None;\n\n  return GetCanonicalHardwareName(device.getValue().str());\n}\n\n// Get inference type attribute from the operation if available.\ninline llvm::Optional<InferenceType> GetInferenceTypeAnnotation(Operation* op) {\n  auto inference_type = op->getAttrOfType<StringAttr>(kInferenceType);\n  if (inference_type == nullptr) return llvm::None;\n\n  llvm::StringRef device_name_str = inference_type.getValue();\n  return GetInferenceTypeEnum(device_name_str);\n}\n\n// InferenceDeviceType is a combination of the hardware with inference type.\nstruct InferenceDeviceType {\n  std::string hardware;\n  InferenceType inference_type;\n\n  bool operator==(const InferenceDeviceType& other) const {\n    return (hardware == other.hardware) &&\n           (inference_type == other.inference_type);\n  }\n\n  bool operator!=(const InferenceDeviceType& other) const {\n    return !(*this == other);\n  }\n\n  struct inference_device_type_hash {\n    size_t operator()(const InferenceDeviceType& p) const {\n      auto hash1 = std::hash<std::string>{}(p.hardware);\n      auto hash2 = std::hash<InferenceType>{}(p.inference_type);\n      return hash1 ^ hash2;\n    }\n  };\n};\n\n// Get InferenceDeviceType attribute from the operation if available.\ninline llvm::Optional<InferenceDeviceType> GetInferenceDeviceTypeForOp(\n    Operation* op) {\n  auto hardware = GetTargetAnnotation(op);\n  if (!hardware.hasValue()) return llvm::None;\n\n  auto inference_type = GetInferenceTypeAnnotation(op);\n  if (!inference_type.hasValue()) return llvm::None;\n\n  InferenceDeviceType inference_device_type;\n  inference_device_type.hardware = hardware.getValue();\n  inference_device_type.inference_type = inference_type.getValue();\n  return inference_device_type;\n}\n\n}  // namespace tac\n}  // namespace TFL\n}  // namespace mlir\n\n#endif  // TENSORFLOW_COMPILER_MLIR_LITE_EXPERIMENTAL_TAC_COMMON_TARGETS_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <string>\",\n        \"component_description\": \"Includes the standard string library, which provides facilities to manipulate strings.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <vector>\",\n        \"component_description\": \"Includes the standard vector library, which provides dynamic array capabilities.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"llvm/ADT/ArrayRef.h\\\"\",\n        \"component_description\": \"Includes LLVM's ArrayRef header for a non-owning reference to an array of objects.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"llvm/ADT/None.h\\\"\",\n        \"component_description\": \"Includes LLVM's None header, which provides the NoneType and OptionalNone type definitions for representing 'no value'.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"llvm/ADT/Optional.h\\\"\",\n        \"component_description\": \"Includes LLVM's Optional header, which provides the Optional template class for values that may or may not be present.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"llvm/ADT/StringRef.h\\\"\",\n        \"component_description\": \"Includes LLVM's StringRef header, which provides a lightweight reference to an immutable string.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"mlir/IR/Operation.h\\\"  // from @llvm-project\\\"\",\n        \"component_description\": \"Includes MLIR's Operation header, which provides the base class for all operations in the MLIR Intermediate Representation.\"\n      },\n      {\n        \"component_type\": \"CONSTANT_DEFINITION\",\n        \"component_name\": \"kDevice\",\n        \"component_code\": \"constexpr char kDevice[] = \\\"tac.device\\\";\",\n        \"component_description\": \"Defines a constant string that represents the attribute key for specifying device information in MLIR operations.\"\n      },\n      {\n        \"component_type\": \"CONSTANT_DEFINITION\",\n        \"component_name\": \"kInferenceType\",\n        \"component_code\": \"constexpr char kInferenceType[] = \\\"tac.inference_type\\\";\",\n        \"component_description\": \"Defines a constant string that represents the attribute key for specifying inference type information in MLIR operations.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"GetInferenceTypeEnum\",\n        \"component_code\": \"inline InferenceType GetInferenceTypeEnum(llvm::StringRef device_name_str) { ... }\",\n        \"component_description\": \"Converts a string representation of an inference type to the corresponding enum value.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"GetCanonicalHardwareName\",\n        \"component_code\": \"inline std::string GetCanonicalHardwareName(const std::string& hardware_name) { ... }\",\n        \"component_description\": \"Converts a hardware name to its canonical uppercase form.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"GetTargetAnnotation\",\n        \"component_code\": \"inline llvm::Optional<std::string> GetTargetAnnotation(Operation* op) { ... }\",\n        \"component_description\": \"Retrieves the target hardware annotation from an MLIR operation, returning it in its canonical uppercase form.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"GetInferenceTypeAnnotation\",\n        \"component_code\": \"inline llvm::Optional<InferenceType> GetInferenceTypeAnnotation(Operation* op) { ... }\",\n        \"component_description\": \"Retrieves the inference type annotation from an MLIR operation as an enum value.\"\n      },\n      {\n        \"component_type\": \"STRUCT_DEFINITION\",\n        \"component_name\": \"InferenceDeviceType\",\n        \"component_code\": \"struct InferenceDeviceType { ... };\",\n        \"component_description\": \"Defines a structure representing a combination of hardware and inference type, with comparison operators and a hash function.\"\n      },\n      {\n        \"component_type\": \"FUNCTION_DEFINITION\",\n        \"component_name\": \"GetInferenceDeviceTypeForOp\",\n        \"component_code\": \"inline llvm::Optional<InferenceDeviceType> GetInferenceDeviceTypeForOp(Operation* op) { ... }\",\n        \"component_description\": \"Retrieves the inference device type annotation from an MLIR operation, combining hardware and inference type information.\"\n      }\n    ],\n    \"overall_description\": \"This header file defines constants, functions, and a structure for handling target annotations in MLIR operations. It includes utilities for extracting and normalizing device and inference type information from operations, facilitating the management of different execution targets and their properties within an MLIR-based compiler or toolchain.\"\n  }\n}"
    },
    "c_21": {
        "input": "<reponame>EricRemmerswaal/tensorflow\n/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_CORE_COMMON_RUNTIME_REQUEST_COST_ACCESSOR_H_\n#define TENSORFLOW_CORE_COMMON_RUNTIME_REQUEST_COST_ACCESSOR_H_\n\n#include <string>\n\n#include \"absl/container/flat_hash_map.h\"\n#include \"absl/time/time.h\"\n#include \"tensorflow/core/common_runtime/request_cost.h\"\n\nnamespace tensorflow {\n\n// An interface for accessing the RequestCost associated with the current rpc\n// request.\nclass RequestCostAccessor {\n public:\n  virtual ~RequestCostAccessor() {}\n  virtual RequestCost* GetRequestCost() const = 0;\n};\n\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_COMMON_RUNTIME_REQUEST_COST_ACCESSOR_H_\n",
        "output": "{\n  \"output\": {\n    \"programming_language\": \"C\",\n    \"components\": [\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include <string>\",\n        \"component_description\": \"Includes the standard C++ string library for handling string operations.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"absl/container/flat_hash_map.h\\\"\",\n        \"component_description\": \"Includes the Abseil flat hash map header, which provides a fast hash map implementation.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"absl/time/time.h\\\"\",\n        \"component_description\": \"Includes the Abseil time library for handling time-related operations.\"\n      },\n      {\n        \"component_type\": \"HEADER_INCLUDE\",\n        \"component_name\": NULL,\n        \"component_code\": \"#include \\\"tensorflow/core/common_runtime/request_cost.h\\\"\",\n        \"component_description\": \"Includes a TensorFlow header file that likely defines the RequestCost class or struct, which is used to track and manage request costs.\"\n      },\n      {\n        \"component_type\": \"CLASS_DEFINITION\",\n        \"component_name\": \"RequestCostAccessor\",\n        \"component_code\": \"class RequestCostAccessor {\\n public:\\n  virtual ~RequestCostAccessor() {}\\n  virtual RequestCost* GetRequestCost() const = 0;\\n};\",\n        \"component_description\": \"Defines an abstract class named RequestCostAccessor. This class provides an interface for accessing the RequestCost associated with the current RPC (Remote Procedure Call) request. It includes a pure virtual destructor and a pure virtual method GetRequestCost(), which must be implemented by any derived classes to return a pointer to a RequestCost object.\"\n      }\n    ],\n    \"overall_description\": \"This C++ header file defines an interface for accessing the cost associated with an RPC request in TensorFlow, a popular machine learning framework. The file includes necessary headers from the standard library and Abseil, as well as a custom TensorFlow header that presumably contains the definition of the RequestCost class or struct. The primary component is the RequestCostAccessor class, which serves as an abstract base class for any classes that need to provide access to request cost information. It declares a pure virtual method GetRequestCost() that must be implemented by derived classes to return a pointer to a RequestCost object.\"\n  }\n}"
    }
}